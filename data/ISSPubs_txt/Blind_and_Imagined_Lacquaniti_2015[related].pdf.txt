"","x"
"1","$33 3'33‘03: MULTISENSORY RESEARCH
7/1 E ‘

B RI L L M ultisensory Research (2015) DOI:10.1163/22134808—00002471 brill.com/msr
GraVIty 1n the Bram as a Reference for Space and
Time Perception
Francesco Lacquaniti1’2’3’*, Gianfranco B0sc01’2’3, Silvio Gravano 2’3 ,

Iole Indovina 2’3 , Barbara La Scaleia 3, Vincenzo Maffei 3 and Myrka Zago 3
1 Department of Systems Medicine, University of Rome Tor Vergata,
Via Montpellier 1, 00133 Rome, Italy
2 Centre of Space Bio-medicine, University of Rome Tor Vergata,
Via Montpellier 1, 00133 Rome, Italy
3 Laboratory of Neuromotor Physiology, IRCCS Santa Lucia Foundation,
Via Ardeatina 306, 00179 Rome, Italy
Received 25 October 2014; accepted 23 December 2014
Abstract
Moving and interacting With the environment require a reference for orientation and a scale for cal—
ibration in space and time. There is a Wide variety of environmental Clues and calibrated frames at
different locales, but the reference of gravity is ubiquitous on Earth. The pull of gravity on static
Objects provides a plummet Which, together With the horizontal plane, deﬁnes a three—dimensional
Cartesian frame for Visual images. On the other hand, the gravitational acceleration of falling Obj ects
can provide a time—stamp on events, because the motion duration of an object accelerated by gravity
over a given path is ﬁxed. Indeed, since ancient times, man has been using plumb bobs for spatial
surveying, and water Clocks 0r pendulum Clocks for time keeping. Here we review behavioral eVi—
dence in favor of the hypothesis that the brain is endowed With mechanisms that exploit the presence
of gravity to estimate the spatial orientation and the passage of time. Several Visual and non—Visual
(vestibular, haptiC, Visceral) cues are merged to estimate the orientation of the Visual vertical. HOW-
ever, the relative weight of each cue is not ﬁxed, but depends on the speciﬁc task. Next, we show that
an internal model of the effects of gravity is combined With multisensory signals to time the inter—
ception of falling Objects, to time the passage through spatial landmarks during Virtual navigation, to
assess the duration of a gravitational motion, and to judge the naturalness of periodic motion under
gravity.
Keywords
Internal model, interception, self—motion, microgravity, vestibular, perceived vertical
* To Whom correspondence should be addressed. E—mail: lacquaniti@med.unir0ma2.it

© Koninklijke Brill NV, Leiden, 2015 DOI:10.1163/22134808-00002471

"
"2","2 F. Lacquaniti et al. /Multisens0ry Research (2015)
1. Introduction
Reference to gravity is crucial to assess the orientation of our body and limbs
in space, to maintain postural equilibrium and move around, to interpret the
outside world and to navigate through it. The mechanisms involved in build—
ing a spatial reference to gravity have been studied extensively, and several
excellent reviews eXist on this topic (e.g., Angelaki and Cullen, 2008; Berthoz,
m Harris et al., 2011; Howard, 1982; Klatzky, 1998; Lackner and DiZio,
L05; Paillard, 1991). Here we consider one speciﬁc but important aspect of
spatial orientation, namely the subjective estimate of the orientation of the Vi—
sual vertical. In this perceptual behavior we see epitomized the key features of
spatial orientation, with the fusion of multisensory information and the role of
a prior expectation of the direction of gravity. We also brieﬂy review the issue
of the spatial orientation cues for the recognition of objects and people.

Next, we concentrate on the much less explored issue concerning the role of
a gravitational reference to mark the timing of actions and perceptions. Con—
siderable work has been carried out in the ﬁeld of time perception and motor
timing, with a special emphasis on the demonstration of time distortions and
what they can reveal about neural timing mechanisms (see for instance, Buhusi
and Meek, 2005; Lewis and Miall, 2003; Mauk and Buonomano, 2004; &
Chant et al., 2013). By contrast, the idea that the brain constantly strives to
maintain accurate time estimates by calibrating them against physical laws
from the outside world has received much less attention (Eagleman, 2004; Q
gleman et al., 2005; Zago et al., 2011a). This hypothesis is especially relevant
for the estimates of the duration of a target motion. Thus, the position of a
moving object at a given time in the near future can be predicted by a forward
internal model (Davidson and WolEert, 2005 ; Zago et al., 2009) and can be
compared with sensory feedback to calibrate the time estimates (Eagleman,
£4). In the second part of this review, we consider some evidence that the
brain takes advantage of an internal model of the effects of gravity to main—
tain accurate time estimates. As in the case of spatial orientation, the time
estimates of gravitational motion also rely on multisensory signals combined
with a prior model of physics. In the ﬁnal part of the review, we discuss the
nature of this internal model and how it can predict the outcomes of realistic
scenarios. We will only brieﬂy mention some neural substrates of the internal
model of gravity, as this issue has been thoroughly covered in a recent review
(Lacguaniti et al., 2013).
2. Subjective Vertical
It has long been known that humans can accurately estimate the direction of
the Earth’s vertical, but the contributing mechanisms have been the topic of

"
"3","Multisensory Research (2015) DOI:10.1163/22134808-00002471 3
continuing debate (see Bisohof, 1974). Kofﬂ<a (1935) proposed that the sense
of the vertical and horizontal is mainly determined by the contours of the Vi-
sual ﬁeld (the horizon, walls, ﬂoors). Objects and our own body posture would
be perceived as upright or tilted only in relation to this Visual reference frame.
By contrast, Gibson and Mowrer (1938) argued that the Visual vertical and
horizontal are not determined by Visual cues but by postural stimuli, and ulti-
mately by the force of gravity acting on the body. A few years later, Gibson
(1952) reconsidered his position in the wake of the apparently contradictory
results obtained by Asch and Witkin (1948) and by Mann et al. (1949). In
the study by Asch and Witkin (1948), perceptual judgments of the vertical ap-
peared to be mainly based on the Visual ﬁeld cues, being little inﬂuenced by
the direction of the pull of gravity on the body. The opposite was found by
Mann et al. (1949) who reported a prevalence of the postural cues. Gibson
(1952) then suggested that the Visual vertical is determined jointly by Visual
and postural (gravitational) cues. He further argued that, in case of a discrep-
ancy between these cues, the brain learns to use the reliable cues and to neglect
the unreliable ones.

2.]. Multisensory Cues t0 Subjective Vertical

Gibson’s hypothesis has been corroborated and reﬁned by subsequent studies,
and we now know that several types of Visual and non-Visual cues contribute
to the subjective estimate of vertical direction (e.g., Angelaki et al., 2009;
Harris et al., 2011; Howard, 1982; Lackner and DiZio, 2005; Mittelstaedt,
£83). The subjective Visual vertical (SVV) is usually tested by asking sub-
jects to align an initially tilted luminous bar with the estimated earth-vertical.
In darkness, SVV of upright subjects deViates by <2O relative to the actual
direction of gravity, but the errors are substantial when subjects are tilted
sideways (Aubert, 1861; De Haes, 1970; Dyde et al., 2006; Howard, 1982;
Mittelstaedt, 1983; Vingerhoets et al. , 2009). In particular, for tilts greater than
about 60°, the true vertical direction is undershot, and SVV is systematically
biased towards the head and body orientation (the so-called Aubert-effect).
Even though the SVV indicates an underestimation of body tilt in such cases,
systematic errors in the tilt signal cannot eXplain the phenomenon alone, be-
cause body tilt perception is almost correct in these conditions (KaEtein and
Van Gisbergen, 2004; Mast and Jarchow, 1996).

Estimates of the direction of Visual motion of a patch of dots relative to
the earth-vertical (De Vrijer et al., 2008), as well as perceptual judgments of
the stability (tendency to fall) of pictures of a human ﬁgurine with implied
motion (LoEez et al., 2009) or of an object (Barnett-Cowan et al., 2011) eX-
hibit the same pattern of systematic errors. In the absence of the effects of
gravity, astronauts tend to associate SVV with their body aXis (Clement and
Reschke, 2008; Glasauer and Mittelstaedt, 1998), and a study with parabolic

"
"4","4 F. Lacquaniti et a1. /Multisens0ry Research (2015)
ﬂight showed that the level of gravity must exceed a given threshold (>03 g)
to be recognized as a reference for SVV (De Winkel et al., 2012).

In general, the perception of orientation in a rich, naturalistic environment
depends on Visual and non—Visual cues (Lacguaniti et al., 2014a). Harris et al.
52011) list the following Visual cues to orientation: (a) the Visual frame identi—
ﬁed by vertical and horizontal contours (walls, ceilings, ﬂoors); (b) the Visual
horizon; (C) the assumption that light comes from above (although it has re—
cently been shown that this assumption is weak, Morgenstern et al., 2011);
(d) the spatial relationship between resting objects and their support; (e) the
orientation of familiar polarized objects (e.g., trees, people, lamps, Chairs);
(f) movement of objects on the ground plane (corresponding to horizontal tra—
jectories) or falling in air (vertical trajectories).

Non—Visual cues to orientation are provided by the otoliths of the vestibular
system, as well as by the skin, muscle and tendon receptors, and by specialized
Visceral receptors (in the kidneys, vena cava, etc.). The otoliths respond to a tilt
of the head relative to gravity, but in general they signal the net gravito—inertial
acceleration, and cannot distinguish between gravitational and inertial compo—
nents (Fernandez and Goldberg, 1976). However, gravito—inertial accelerations
can be disambiguated by combining the otolith signals with the signals of
the semicircular canals (Angelaki et al., 1999; Glasauer, 1992; Merfeld et al.,
g9). Notice that, in addition to the SVV test, the subjective vertical can also
be assessed haptically (e.g., Bortolanii et al., 2006). In the latter task, blind—
folded subjects manually align a rod with the estimated gravitational vertical.
This approach has the advantage of being unaffected by the vestibulo—ocular
reﬂexes. Moreover, the subjective vertical has been assessed studying self—
paced saccadic eye movements (Barnett—Cowan and Harris, 2008; Pettorossi
et al., 1998). Thus, subjects asked to perform saccades along the direction
of gravity in the dark are fairly accurate when upright, but they eXhibit the
Aubert—effect when tilted.

2.2. Modeling Multisensory Interactions for Subjective Vertical

To determine the relative role of Visual, gravity—related and body—related ori—
entation cues, Dyde et al. (2006) presented the luminous bar of the SVV test
against a highly polarized Visual background. The Visual background and body
orientation could be tilted independently. Following Mittelstaedt g 1983), they
modeled the perceived vertical as a weighted vector sum of the different ori—
entation cues, the weights depending on the relative reliability of each cue
(Fig. 1).

Dyde et al. 52006) found that the inﬂuence of Vision in the SVV test is
small, contributing only about 8% of the information, compared to 77% from
gravity and 16% from the long aXis of the observer’s body. This is very differ—
ent from what is found if, instead of a luminous line, a more complex Visual

"
"5","Multisensory Research (2015) DOI:10.1163/22134808-00002471 5
:fl
vision _, h... »
"" 3%. 1; “g ‘1‘( i"" '.
K1» 1 ﬁ ﬁll“. vector sum
k -' ‘bcﬂi'n” :3. ‘
. I‘ cé'v :- ' I. ""Dr
' 6 Rx: \ ,*
1.1-..- . ,.
Figure 1. Model proposed by Dyde et al. (2006) for the subjective estimate of the upward direc-
tion. The vector sum of gravity, body orientation and Visual cues corresponds to the estimated
upward. This ﬁgure is published in colour in the online version.
object is shown to probe the perception of upright. T hus, in the oriented char-
acter recognition test (OCHART), observers are asked to report whether they
see the letter ‘d’ or the letter ‘p’ When the corresponding symbol is presented
at various orientations (Dyde et al., 2006). Using this test, it has been found
that Vision contributes about 27% of the information needed to determine the
perceptual upright, compared to about 13% from gravity and 60% from the
body (Barnett—Cowan et al., 2013). OCHART has also been performed dur-
ing parabolic ﬂight (Harris et al., 2012) and during centrifuge tests simulating
levels of gravity from zero to earth’s gravity along the long-aXis of the body
(Harris et al., 2014). In contrast with SVV (see above), low levels of gravity
such as that of the moon (0.16 g) have been shown to be sufﬁcient for main-
taining a similar weighting as on ground of the cues determining the perceptual
upright, i.e., Vision, body and gravity-related cues (Harris et al., 2014).
Statistically optimal Bayesian models have also been used to predict SVV
responses (Clemens et al., 2011; De Vrijer et al., 2008; MacNeilage et 611.,
M). T hus, the inputs to a Bayesian model are represented by the head ori-
entation in space and the Visual orientation of the luminous bar relative to
the retina. While the Visual signals are precise, the head tilt signals are noisy.
However, these tilt signals are combined with a prior assumption that the head
and the body are most likely oriented near the vertical, resulting in a statis-
tically optimal estimate. This prior assumption is somewhat equivalent to the
idiotropic component of the vectorial model of Mittelstaedt (1983). Visual—
vestibular combination also contributes to the perception of heading direction,
each cue contributing to the precision and accuracy of the estimates (Zaidel
et al., 2013). Related to this point, representation of self—motion in three-
dimensional (3D) space has been shown to be non-uniform (Barnett—Cowan

"
"6","6 F. Lacquaniti et a1. /Multisens0ry Research (2015)

et al., 2012; see also Section 4.4), and it has been suggested that this percep-
tual anisotropy arises as a consequence of righting reﬂexes that tend to keep
the head upright along with the prior assumption of the head being upright
(Barnett-Cowan and Biilthoff, 2013).

3. Spatial Orientation Cues for the Recognition of Objects and People
We typically interact more easily with objects When they are upright (the right
way up). We already mentioned the issue of recognizing ambiguous Characters
at different orientations (OCHART). Here we brieﬂy summarize other exam-
ples of object recognition problems. ‘Right-way-up’ can be deﬁned relative to
a variety of biologically relevant reference frames, such as the Viewer-Centered
frame, the gravity-centered frame, and the Visual frame (Howard, 1982; Lac-
quaniti, 1997). Thus, recognition of scenes, people and actions tends to be
faster and more accurate When they are aligned with the observer, whether both
the scene and the observer are upright or they are both tilted (e.g., Chang et al. ,
w Dyde et al., 2006; Kohler, 1940; Kushiro et al., 2007; Troje, 2003; m
g9). For instance, When a digitally edited photograph of a face is presented
upside-down relative to the observer, the ability to detect gross distortions
and abnormalities is strongly impaired (Lobmaier and Mast, 2007; ThomE-
son, 1980). Similar Viewer-Centered inversion effects have been described for
the discrimination of static Whole-body postures (Reed et al., 2003) and of bi-
ological motion in point-light walker stimuli (e.g., Chang et al., 2010; Pavlova
and Sokolov, 2000; Sumi, 1984; Troje and Westoff, 2006).

Even though a Viewer-Centered reference frame may allow optimal process-
ing of object properties in the canonical perspectives and although egocentric
cues dominate in the encoding of Visual scenes, allocentric cues contribute
as well. Thus, observers are sensitive to the artiﬁcial inversion of the Visual
effects of gravity on the motion of inanimate objects (Bingham et al., 1995;
Indovina et al., 2005). Also, a role of orientation relative to gravity has been
documented for processing global and local motion cues of point-light walker
stimuli, presumably in connection with expectations about the dynamics of the
body due to gravity (Chang and Troje, 2009; Shigley, 2003; Troje and West-
hoff, 2006).

It has also been shown that the View of a rotated photograph or Video-Clip
with strong ‘up’ and ‘down’ polarization cues can alter the perceived direc-
tion of physical ‘up’ and ‘down’ directions (Dyde et al., 2006; Jenkin et al.,
w, a 1). Thus, perceptual biases have been documented in relation to the
orientation of the stimuli relative to gravity (Chang et al., 2010; Lobmaier and
Mast, 2007; LoEez et al., 2009) and to intrinsic Visual references (Jenkin et
al., 2004).

"
"7","Multisensory Research (2015) DOI:10.1163/22134808-00002471 7

Finally, allocentric Visual cues can inﬂuence mental transformation of bod—
ies. Preuss et al. 52013) used the York Tumbling Room to modulate the
allocentric Visual reference frame and the perceived orientation of the body
relative to gravity. They found that body stimuli with a Visual polarity relative
to the environment were more accurately identiﬁed when the room and the
body stimuli were aligned. Instead, this congruency did not facilitate identify—
ing hand stimuli that do not have Visual polarity relative to the environment.
4. Subjective Time Estimates
Time information is analyzed across a wide range of intervals, from the
microsecond timing of sound localization to the 24—h period of Circadian
rhythms. While an intriguing relationship between the macular receptors and
the Circadian timing system has been shown (Fuller and Fuller, 2006), here we
concentrate on events unfolding over the scale of tens to hundreds of millisec—
onds, a time scale critical for rapid interactions with the environment.

Time is not directly measured by the nervous system, but is estimated by in—
tegrating appropriate information over discrete intervals using internally gen—
erated and/or externally triggered signals (see Eagleman et al., 2005; Fraisse,
1963). Because of the complex, context—dependent interplay of internal and
external factors, the estimates of elapsed time in the sub—second range can
be distorted (Eagleman, 2008; Haggard et al., 2002; Lacguaniti et al., 2014b;
Orgs et al., 2013; Zago et al., 2011a). Thus, the perceived duration of a generic
moving stimulus is longer than that of a stationary stimulus with the same
physical duration (Brown, 1995; Kanai et al., 2006), and it increases with in—
creasing speed (Kaneko and Murakami, 2009). Moreover, a constant—speed
motion appears to last longer than a decelerating motion, and the latter ap—
pears to last longer than an accelerating motion (Matthews, 2011). Also the
predictive estimates of the time remaining before a collision (so called time—
tO—Contact, 0r TTC) can be inaccurate in the case of generic accelerating 0r
decelerating motion, as shown by the errors in interception (Port et al., 1997).

Temporal biases in action and perception may actually fulﬁll a speciﬁc
function, e.g., improving agency (temporal binding effect, Moore and m
a 2), enhancing Visual processing during action preparation (Hagura et al.,
Q2), support apparent movement perception (Orgs et al., 2013) and aC—
tion discrimination (Carrozzo et al., 2010). On the other hand, accurate time
estimates that reﬂect veridical physical duration are desirable in other cir—
cumstances, such as catching a ball or escape from an approaching preda—
tor. Therefore, there must CO—eXist distinct mechanisms that support cogni—
tion/perception by distorting subjective time in a principled and purposeful
manner, and mechanisms that improve the accuracy of temporal estimates
when timely reactions are needed.

"
"8","8 F. Lacquaniti et a1. /Multisens0ry Research (2015)

One speciﬁc mechanism that can keep time estimates calibrated takes ad-
vantage of the fact that objects’ motion under gravity represents a highly
predictable event, with a ﬁxed duration over a given path. Indeed, there is much
evidence that prior knowledge about gravitational force is incorporated in the
neural mechanisms computing elapsed time (e.g., Indovina et al., 2005; %
guaniti et al., 1993; McIntyre et al., 2001; Moscatelli and Laoguaniti, 2011;
Zago et al., 2004). In particular, an internal model of the effects of gravity has
been shown to be applied to both automatic sensorimotor processes and some
cognitive judgments of elapsed time.

4.]. Timing oflnterceptive Movements

It has been shown that the manual interception of a ball in vertical free-fall
(e.g., Brenner et al., 2014; Lacguaniti and Maioli, 1989b; Zago et al., 2004;
see Fig. 2), rolling down an inclined plane Q Scaleia et al., 2014a; Mijatovié
e_t al., 2014; see Fig. 3), or in ballistic projectile motion (Bosco et al., 2012;
Cesgui et al., 2012; D’Andola et al., 2013) is accurately timed, even in blind-
folded subjects provided with an auditory cue on ball release (Lacguaniti and
Maioli, 1989a). The effects of gravity are also taken into account in the ocu-
lomotor behavior necessary to track projectile motion (Delle Monache et al.,
2014; Diaz et al., 2013).

On the other hand, the interception of targets descending vertically under
non-ecological conditions is generally inaccurate (Figs 2, 3). Thus, astronauts
move their arm too early to catch a weightless approaching target, as if they
still anticipated the effects of earth’s gravity (McIntyre et al., 2001). Similar
results are obtained by simulating lack of gravity or reversed gravity on Visual
motion in the laboratory (Indovina et al., 2005; Zago et al. , 2004). Interception
timing under both normal and abnormal gravity conditions can be explained by
assuming that Visual on-line information about target position and velocity is
combined with a prior of earth’s gravitational acceleration (Gomez and Lopez-
Moliner, 2013; McIntyre et al., 2001; Zago and Lacguaniti, 2005a; Zago et al.,
$4). This model is somewhat reminiscent of the Bayesian formulation of
the SVV problem reviewed above, in so far as it involves statistical informa-
tion derived from both current sensory inputs and past experience. However,
the prior of gravitational acceleration appears to be surprisingly resistant to
Changes in the face of new sensory evidence. In fact, under conditions Violating
earth’s gravity, interception performance is improved by using sensory feed-
back and performance errors to adjust internal time-delay parameters, Without
modifying the prior of acceleration (McIntyre et al., 2003; Zago et al., 2005 ;
Zago and Lacguaniti, 2005b, C).

"
"9","Multisensory Research (2015) DOI:10.1163/22134808-00002471 9
hwgn—o—o—o
% 2': a 3 a a
. cc:
.2 E B ‘D 33 1: 8
1: cc: ..8 g 53 9-1
‘ Dwﬂgo m 8
M17} 1"" 7 r V C‘ L ‘ “ Li -—4 M >4 ‘_/ Lj ._, A. V _. A ‘.. “ ,H > 7‘“ DO O DO 0 ny—4
:7 ‘7? L77 Q gﬂggwwﬁa. oo—OO “ m H D
j  ‘H1 “ qﬁvog'do
, .. m 1 ““Hr“""‘*""““'w”~ M “—5 H a) D a
, ‘_ .J _4_ _1._.___.._H_. > G) a) E'HU ‘3
1%yu. ﬂ} \ ‘1 O H a) .0 a E
V ""\; (.1 ’J— (.1 _I_>_‘ .7..'..“..,... ,.\_ ‘k, a D m 8 5 3 H
, HH 7' ~~LHFJWT‘HMWAMJ7A (1)8 <08 :0 >3
\ IIi 5H1‘1‘7-1--—~~--+f 33 ""U Ex: ‘53:) 33
4’: ’ “1:1"" 5 g g a 5 H ‘3
pm 7‘” 8*oseooafo
. '—£ :~*7‘7:r;%;;;:7 <=- .ﬁ 5 o=~.a:3.2
:“fﬂ1‘“‘“1 7""*{‘1”?“ Nnosgwﬁ
_—-4 L: ; u ‘L_‘ .-L-H ‘;~‘_ 5 9.4 4—) O ”—4
¢ ~~I'Fﬂ ~
’H;L“rF~}H‘1v-”r( —{ .3: m H'"" C“ ""‘
\I‘F'fl 1:”~‘“K/T”“‘”‘”“ 5 0.5 o:
* a» liarﬁP4-‘r4rw~ N t”§;%.; 5:: d
’quLTfJLik; Bsﬁggegg
j M ‘ i \ 0v ”—4: ‘
- L‘H ';’7[‘*“"""" ~-{* ﬁn %E b o?“ 33
HL___J_J__J-.__L_p_._‘_..u..l OF: G) CS 5.2 >
H .>: H E b
(DA G) D
H <0 “H coo ‘3 9
O Q—‘ H O H HH'F‘
O 'H 0 OD“ cc: o a)“
O m G >~.*""*"" 00:
DHFU ““5
""H q) (D Q Q)“
v-Q': D m G) H
5 W35 0 o 9
(0': H —1 89—4.“
0 “v2 8 0 QB 15
wow 6? 5 ‘9 8 b o o
O a) B“Hﬁ 8 87:
O H mg 8 .,_. Q
N o oqudH
vm E3 5.4 H Q C“ Q
13 . G): D C“ N.E”—‘
8‘ >2: 'yagaﬁ—lgzxxw o x g g '6 o a m“ o 2
"""" 5'."" "" ,b’fl’: 1
\ \ ’ '4: """" G) H m DOUF‘
\ 0.5—5 ‘3 H s_0
‘ 00¢) a cow CS 0 5
“—0 q) G) <1)H >‘Q-4
o ‘4—4 G) 8 H 559'”
0 0'0 H O ""U G)
Ln ""UFO o H d) H
' ﬂaaﬁoﬂwa
5 %mwsd§c:
a H E; 3.2 m 94m
.H'SHHE; QUE
O H C3—‘ (1) 5.4“ Q
d) :6 Q
8 &%35% 8 2H
' v 33E? 8 >893
l—I “E a) cum mg
a o aqﬁ .
o H 5.5.“ d) O E
8 a = H: :0 a 8 <3
‘— H92 Q C; :‘5'5 CL
52 ES 0.“ '53 ‘3 U
a a 8 E 8 cog g
OH O #4.: ”—4
E: m a) o a) ‘3 cc:
9 q) :6 (1): ""SU a
O >5:H 8H 9 a)
Ln 4—> O :3
0—1 4—> (DH H
a 8‘“ o N M a
on H 3 > “c:csg 3
A a c“ @3355qu
m ”—4 QQFUM “D“
m /,/ 4, -7 17,. 0V 0-H O H “S: Q)
‘— , , cu sas_o 0 H m
E 5 U 5.4 (D 30.5: G
a: 9-1 a a) s cc: 0 s O
“H 943.30 5 q) <0
O %273 $394 H 8
co u—4 O Q)
8 aiEBHHSE
.5 8 Bv-g “E"": 5
o O H E; a 3.9
:5 m?) o; v hm“
*5 2"" § “ Eé‘a
0
§ 2 O @853) E 8 6%?
8 UomladaJ ‘— T (\i E e .5 O a 8 4—>
cs: :32 5H 60
v a 0 H .e :5
N.) m 0 Q cg (DH
""‘ O a 0 C“ o'H
LETS.“ CS 9484a B

"
"10","10 F. Lacquaniti et a1. /Multisensory Research (2015)
A C
NORMAL
,J
E
// \\ I I I . V / \ REVERSED
y / \ y \\
| / i \ l , \
B
30° 45° 60° D

110 110

90 90

70 70
E 50 E 50
E 30 E 30

10 T 10

-10 -10

-30 ‘ _ -30

550 610 670 730 550 610 670 730 350 610 670 730 20° 30° 40° 50°
nBMD (ms) Plane Inclination

Figure 3. Left column. (A) In the experiments of La Scaleia et al. (2014), a real ball rolled
down an incline with a kinematics that differed as a function of the starting position and slope
angle, and subjects had to punch it after its eXit from the incline. (B) Timing errors (TE) for
each condition (slope angle and duration of ball motion, nBMD). Responses were well within
the theoretical margin of error for successful punching (grey area). Right column. (C) In the eX-
periments 0f Mij atOVié et al. (2014), subjects pressed a button to intercept a Virtual target sliding
along an inclined plane, either downwards under normal gravity or upwards under artiﬁcial re-
versed gravity. Target motion was occluded from View over the last segment. (D) Difference
in timing error (DTE) between the reversed gravity and the normal gravity conditions. The re-
sponses in the condition with unnatural forces were systematically delayed relative to those with
natural forces. This ﬁgure is published in colour in the online version.
4.2. Multisensory Information for Timing Interceptions
Interception timing is thus driven by an internal model of the effects of grav-
ity, combined with sensory information. In addition to Visual on-line signals

"
"11","Multisensory Research (2015) DOI:10.1163/22134808-00002471 11
about target motion, also proprioceptive neck and vestibular signals contribute.
In one study, subjects intercepted a looming ball shown in a head—mounted
stereoscopic display (Senot et al., 2005). They either pitched their head back—
wards looking up towards the ball descending from a Virtual ceiling (‘above’
condition), or they pitched their head downwards looking down towards the
ball rising from a Virtual ﬂoor (‘below’ condition). The Visual reference frame
for up and down was therefore roughly aligned with physical gravity. Subj ects
generally responded earlier for ‘above’ than for ‘below’. Moreover, inter—
ception rate was higher when balls accelerated or decelerated in a manner
congruent with the direction of movement. Indeed, the success rate for accel—
erating approaches was higher for ‘above’ than for ‘below’, and higher for
decelerating balls for ‘below’ than for ‘above’. The same asymmetry of re—
sponses between ‘above’ and ‘below’ conditions was observed when subjects
were lying down on the laboratory ﬂoor with their body aXis orthogonal to
gravity (Le Séac’h et al., 2010). In contrast, no asymmetry of responses was
found in an experiment in which the Visual conditions of ‘above’ and ‘be—
low’ were reproduced while the subject held the head in a normal, horizontal
posture, thus with the Visual reference for Virtual up and down roughly or—
thogonal to physical gravity (Senot et al. , 2005). Overall, these results indicate
that the adjustments of motor timing were based on vestibular and neck pro—
prioception indicating the expected direction of ball motion with respect to
gravity.

Further evidence for a contribution of otolith sensors in the timing of Vi—
suomotor responses to aceelerating/decelerating targets was obtained during
parabolic ﬂight (Senot et al., 2012). During each parabola, a weightless phase
of about 20 s is preceded and followed by 20 s of hypergraVity. During the
transition from hyper— to hypograVity, saccular afferents in the otoliths brieﬂy
overshoot the O—g—level, as if they sensed a negative gravity, i.e., a gravita—
tional pull in the upward direction. Consistent with this reversal of the otolith
responses, the timing of the interceptive responses in the Virtual environment
described above (Senot et al., 2005) also reversed sign during the weight—
less phases compared with the responses at normal gravity (Senot et al.,
& 2).

As in the case of the perception of subjective vertical, also the deﬁnition of
‘up’ and ‘down’ for timing an interception is a multimodal process that can
involve both allocentric and egocentric information. The experiments of W
et al. 52005, £12) involved a reduced Visual scene, resulting in a predominant
contribution of cues aligned with physical gravity. Instead, Miller et al. (2008)
used a richer, more strongly polarized Visual scene, and found that response
timing was systematically better for downward accelerating versus downward
decelerating balls even when subjects lied on their back and the vertical of
the Visual scene was aligned with the body and orthogonal to physical gravity

"
"12","12 F. Lacquaniti et al. /Multisens0ry Research (2015)

(Fig. 4). The bias for Visual gravitational motion disappeared with a blank
scene. Therefore, when the Visual scene is naturalistic and strongly polarized,
the scene vertical can predominate, driving the perceived direction of free—
fall away from physical gravity when this deviates from the Visual vertical
(a winner—take—all mechanism).

Zago et al. g2011b} manipulated the alignment of Visual gravity effects and
structural Visual cues between each other, and relative to the orientation of the
Observer and physical gravity (Fig. 5). A factorial design assessed the effects
of the scene orientation (normal or inverted) and the direction (normal or in—
verted) of Virtual gravity affecting target motion. They found that the success
rate of interception was signiﬁcantly higher when the orientation of the scene
was concordant with the direction of the gravity that affected target motion,
irrespective of whether both directions were upright 0r inverted. These results
show that the Visible inﬂuence of Virtual gravity and pictorial cues can out—
weigh both physical gravity and Viewer—Centered cues; subj ects tend to rely on
the congruence 0f the apparent physical forces acting on people and objects in
the scene.

4.3. Perceptual Estimates ofFree-Fall Duration

J ust as in the case of sensorimotor processes involved in interception, also cog—
nitive judgments of elapsed time can engage an internal model of the effects of
gravity (see Zago et al., 2011a). Grealy et al. 52004} showed that blind—folded
subjects throwing a ball in the air can accurately indicate when the ball will
hit the ﬂoor. Their results on the estimated temporal durations were well ac—
counted for by a tau—guide model (Lee, 1998) that takes gravity into account
(Georgolgoulos, 2002). Similar results were reported for the indication of the
time of landing of a computer—animated target that rolls Off a horizontal surface
and falls hidden from View (Huber and Krist, 2004). Moscatelli and Lacguaniti
52011} showed that perceptual time discriminations are systematically better
when the linear motion of an Object complies with gravitational constraints
than when it artiﬁcially Violates such constraints. Thus, the duration of a tar—
get accelerating downwards was discriminated more precisely than that of
the same target accelerating upwards, rightwards, 0r leftwards, irrespective
of whether target motion was embedded in a pictorial scene including several
metric cues (familiar size, linear perspective, shading, and texture gradient) or
it was embedded in a blank scene lacking any metrics. However, the gravity—
related anisotropy was more pronounced in the former than in the latter case.
The same study addressed the issue of whether the sensitivity to gravitational
constraints is tied to egocentric coordinates, Earth’s gravity, or Visual refer—
ences intrinsic to the scene. To this end, the same stimuli as before were used,
but the Observer was tilted by 450 relative to the monitor and earth’s gravity in
one experiment, while the Observer was upright and the monitor was tilted by

"
"13","Multisensory Research (2015) DOI:10.1163/22134808-00002471 13
/ I
' ; . , a o
r, I l
. f I f r ' If
.' 7-"" ', ' ii"", I
{H i ,i L z: J/-‘ '
’('- ‘ _‘ /_ ,-
.-,° ' ‘ é IaI ; ‘ non-plctonal
100
50 l
E,
LU
[—
o:
-50
-1 00
-1 50
pictorial non-pictorial
Figure 4. In the experiments of Miller et al. (2008), a Virtual ball was launched vertically from
the red box, rebounded at the trajectory apeX, and returned to the starting point where it had
to be intercepted. In g trials, target acceleration was consistent with natural gravity, that is, the
target decelerated while moving up and accelerated while moving down. In rg trials, instead,
target acceleration was reversed relative to natural gravity, that is, the target accelerated while
moving up and decelerated while moving down. Target motion was embedded in a pictorial
context (top left) or in a blank scene (top right). Bottom panel: Response timing errors (RTE) as
a function of target motion (g vs. rg) and Visual context (pictorial vs. n0n-pict0rial). Responses
were timed systematically better for downward accelerating (white bar) versus downward de-
celerating (black bar) balls with the pictorial scene, but this facilitation disappeared with the
n0n-pict0rial scene. This ﬁgure is published in colour in the online version.

"
"14","14 F Lacquaniti et a1. /Multisensory Research (2015)
—A————@r —B——i_@—'
2 "" ~ \“J H “<i-
_ ----- ” .. ., ./ ‘ \ 5 .. ,1 ’ i. .s / “ \- 5 ,. .. :1
_ﬂ_
1
0,8 l
3
9 0,6
a
(D
8 0,4
D
‘1')
0,2
0
A C B D
congruent incongruent
Figure 5. Effect of Visual congruence between background and gravity orientation. Top panels:
In the experiments of Za 0 et al. 2011b , the Virtual ball was launched vertically from the
launcher, hit the opposite surface and bounced back. The target decelerated from launch to
bounce (blue trajectory), and it accelerated after bounce (red trajectory). When subjects pressed
the button, the standing person in the scene shot a bullet toward the interception point (cross-
hair). The direction of the scene (‘s’) and the direction of Virtual gravity acting on the target
(‘g’) were varied in different blocks of trials: (A) normal scene and gravity, (B) normal scene
and inverted target gravity, (C) inverted scene and gravity, (D) inverted scene and normal target
gravity. Bottom panel: Success rate for each condition. Success rate was signiﬁcantly higher for
the congruent scenes (A and C) than for the incongruent ones (B and D). This ﬁgure is published
in colour in the online version.
45° in another experiment. In both experiments, the pictorial downward was
tilted relative to the retinal vertical meridian. It was found that the discrimi-
nation precision was still higher for targets directed downwards relative to the
pictorial vertical, although the size of the effect decreased with tilting. By con-
trast, the anisotropy essentially disappeared with the non-pictorial scene when

"
"15","Multisensory Research (2015) DOI:10.1163/22134808-00002471 15
target motion was Oblique. The difference in precision between downward and
upward motion varied in a graded manner as a function of the conditions, be—
ing highest when both the Observer and the pictorial scene were upright, and
being lowest when the target direction in the non—pictorial scene was tilted by
450 relative to an upright Observer. The results were modeled using a linear
combination of pictorial cues, orientation of the Observer, and orientation of
target motion relative to the physical vertical (reminiscent of the approach of
Dyde et al., 2006, mentioned above). The resulting weighing coefﬁcients were
43, 37, and 20% for Observer orientation, target motion orientation, and picto—
rial cues, respectively. The fact that the weight of egocentric cues specifying
the Observer’s orientation was highest in this task is in line with previous work
on the perceptual discrimination of scenes, people and actions (e.g., Chang et
al., 2010). Also, the substantial contribution of Visual references intrinsic to
the scene, such as the direction of target motion and the presence of additional
pictorial cues, agrees with the previous observation that Viewing a picture with
strong polarization cues (indicating relative up and down directions in the pic—
ture) affects the perceived direction of up and down directions in the real world
(J enkin et al., 2004).

4.4. Time-to-Passage During Passive Self-Motion

The Visual effects of gravity also contribute to time estimates during self—
motion in the vertical direction. In the studies by IndOVina et al. (2013a,
b), stationary subjects experienced Virtual rides on a r011er—coaster in a ﬁrst—
person perspective (Fig. 6). These Visual stimuli provide an immersiVe sense
of presence in the Virtual environment, compatible with forward self—motion
(Baumgartner et al., 2008; IndOVina et al., 2013a, b). The r011er—coaster ye—
hicle moved along vertical or horizontal rectilinear sections, connected by
curves. Acceleratiorﬂdeceleration was coherent with gravity for vertical m0—
ti0n, whereas the same aceeleration/deceleration was unnatural for horizontal
motion. In one experiment, the vehicle traveled in the Open, through vari—
ous mountain landscapes. In a second experiment, the vehicle traveled within
dark tunnels during the ﬁnal part of the path to eliminate Visual cues. Sub—
jects pressed a button when they thought the vehicle passed through a given
reference point. The results showed that gravitational acceleration was taken
into account, for both Visible and occluded conditions. In particular, time—
tO—passage was indicated earlier when the vehicle accelerated downward at
1 g (as during free fall), as compared to when the same acceleration occurred
along the horizontal direction. Since the motion law was the same for the two
conditions, this difference must be related to the Visual context that deﬁnes
the orientation of the motion, vertical or horizontal. Moreover, the precision in
time—tO—passage estimates was higher during accelerated falls than constant
speed motion along vertical tracks (IndOVina et al., 2013a). This result is

"
"16","16 F. Lacquaniti et a1. /Multisensory Research (2015)
Vertical Upward
' a n w
i .9. ‘ .4:
/ l :l ‘- _ / l | ‘- ‘ V - H
Vertical Downward a 30 *9:
g 20 —’
-- E2 10
.H
/, ! i a 0
7/5: 'I I 1 / l ‘l ! E -10
/ ‘vl ,.[/ I'| Q -20
. _30 9: 9:
Horlzo “133' 1 -, Va-Ha Vc-Hc Vd-Hd
4., -
/ \‘1‘ I‘ 3 7 , I,
P“ 1': .‘ ___ I"" lnl .__*\
Figure 6. Time-tO-passage during passive self—motion. In the experiments of IndOVina et al.
(2013a), subj ects riding a Virtual r011er-coaster pressed a button at the time at Which they thought
the rollercoaster car passed through a reference point. Left: Still frames from animated Visual
stimuli simulating the r011er-coaster ride. Vertical and horizontal tracks are shown at the onset of
the trial and at about 2 m before crossing the passage reference point. Right: Difference between
time-tO-passage (DTTP) during vertical motions and that during horizontal motions, plotted as
a function of motion law. Va, vertical accelerated; VC, vertical constant speed; Vd, vertical de-
celerated; Ha, horizontal accelerated; He, horizontal constant speed; Hd, horizontal decelerated.
The results show a signiﬁcant anticipation in the time-tO-passage estimate during the vertically
accelerated downward motion (free fall) When compared With accelerated horizontal motion.
This ﬁgure is published in colour in the online version.
consistent with a lower noise in time estimates When the motion complies
with the gravitational constraint as compared to When the motion violates
the constraint, consistent with the results obtained by Moscatelli and Lao-
quaniti (2011). Notice that perceptual asymmetries for self—motion have also
been reported for physical self—motion, in this case the sensitivity for vertical
translations being lower than that for horizontal translations and sensitivity for
downward motion being higher than for upward motion (Nesti et al., 2014).
4.5. Perceptual Judgments ofPeriodic Events
In general, the timing of periodic events is highly predictable because a regu-
lar time interval can be used as a predictive template (M6). While the
temporal reference in an auditory rhythm typically corresponds to the ‘beat’

"
"17","Multisensory Research (2015) DOI:10.1163/22134808-00002471 17
(Large, 2008), a periodic Visual motion contains time—varying spatial informa—
tion and the reference may be deﬁned by several different parameters in the
trajectory identifying a Visual ‘beat’ (Luck and Sloboda, 2007). Su (2014) con—
siders that Visual motion can be perceptually segmented using velocity peaks
and distinct spatial positions, such as path reversals.

Both path reversals and the velocity proﬁle can be used when judging the
period of oscillation of a pendulum, another familiar example of gravitational
motion. Several inanimate and animate (biological) motions are described ap—
proximately as a pendulum. For instance, the body and limbs oscillate as
a multi—jointed pendulum during walking. Indeed, gravitational information
contributes to the recognition of walking movements (Maffei et al., 2015;
Shigley, 2003; Troje and Westoff, 2006).

There is considerable evidence that pendulum motion is perceptually
salient, inasmuch as artiﬁcial deviations from the normal relation between
pendulum period and pendulum length are Visually detected (Bozzi, 1958;
Frick et al., 2005; Pittenger, 1990). Thus, in experiments in which a pendu—
lum is made artiﬁcially to oscillate faster or slower than normal, the observers
rate the oscillations Violating the physical length—period relation as less natu—
ral than the oscillations complying with physics (Pittenger, 1990). Moreover,
observers discriminate between the patCh—light display of a freely swinging
pendulum and that of a hand—moved pendulum with the same period and am—
plitude. However, discrimination is impaired when the pendulum is shown
upside—down (Bingham et al., 1995).

One psychophysical approach to discover an implicit bias toward gravi—
tational motion when Viewing an oscillating pendulum is based on the idea
that the brain takes into account the statistics of environment stimuli, and in
particular it is biased toward events that occur more frequently, relying on a
statistical prior model of the natural environment (Barlow, 1959; Simoncelli
and Olshausen, 2001). Runeson 51974) developed this argument further and
proposed that the speed of a Visual stimulus is estimated with reference to
a natural motion with a compatible trajectory. Whenever speed Changes are
consistent with a natural dynamic event, they are not taken into account, and
speed is perceived as approximately constant. Consistent with Runeson’s hy—
pothesis, La Scaleia et al. (2014b) showed that the quasi—harmonic motion of
a point—light target oscillating like a simple pendulum is perceived as uniform,
but this bias disappears when the stimuli are incompatible with a pendulum
(Fig. 7).

5. Discussion
We argued that the brain is endowed with mechanisms that exploit the ef—
fects of gravity to estimate spatial orientation and time. These mechanisms

"
"18","18 F. Lacquaniti et al. /Multisens0ry Research (2015)
A
A
V
A
V
B
200
150
100
50
0 5 10 15 20
-1g 0g 1g 2g 3g
Condition
C
1 f ,/ ,
/( //// ‘/
t / ,l
0.5 ,. //
l” l l
0 5 10 15 20
-1g 0g 1g 2g 3g
Figure 7. Implied gravity in a pendulum motion biases the Visual perception of speed (experi-
ments of La Scaleia et al., 2014b). (A) In one experiment, the target oscillated back—and-forth
along a circular are around an invisible pivot (leftmost and middle panels). The imaginary seg-
ment from the pivot to the midpoint of the trajectory could be oriented vertically downward
(consistent With an upright pendulum, leftmost panel), or vertically upward (upside-down, mid-
dle panel). In another experiment, the target moved uni-directionally, anticlockwise on a circular
trajectory, being Visible only in the bottom and top quadrants (rightmost panel). In all experi-
ments, the target shifted according to one of 21 different kinematic conditions, including both
harmonic and constant speed motion, and the observers were asked to choose the proﬁle that
appeared most uniform. (B) Distribution histograms of the responses (pooled over all partici-
pants) for the conditions illustrated in A. Abscissae: motion conditions: —1 g corresponds to
a target moving under reverse gravity; 0 g, constant-speed motion, 1 g, motion under natural
gravity; 2 g and 3 g, motions With maximum velocity twice and three times as large as l g, re-
spectively. Ordinates: number of responses. Blue (black) bars: 0 g; red (grey) bars: 1 g. (C) Cu-
mulative distribution functions for each participant (black) and for the population (red). The
results show that, for both pendulum orientations (leftmost and middle columns), the respon-
ses clustered around the kinematic proﬁle simulating the effects of a Virtual gravity (1 g) acting

"
"19","Multisensory Research (2015) DOI:10.1163/22134808-00002471 19
are built so as to match environmental structure. For instance, Visual images
of natural scenes are anisotropic, with more image structure at orientations
parallel or orthogonal to the direction of gravity (e.g., Hansen and Essock,
£4). These image anisotropies are matched by corresponding anisotropies
in perceptual responses. Thus, line and motion directions are discriminated
better when they are oriented vertically or horizontally (cardinal directions)
than when they are oriented obliquely (AEEelle, 1972; Ball and Sekuler, 1987).
As reViewed in a previous section, anisotropy related to the direction of mo—
tion has been described also in a task of time perception, the discrimination
of temporal duration being better for vertical downward motion that for other
directions of motion (Moscatelli and Lacguaniti, 2011).

By taking advantage of a structured environment, not only does the brain
improve spatial and temporal estimates about current events, but it is also able
to shape accurate expectations about forth—coming events. Predictive behaVior
can improve perception by anticipating the ‘what’, the ‘when’ and the ‘where’
of probable stimuli (Huron, 2006), and can facilitate more appropriate motor
responses (Zago et al., 2009). Considerable sensory—motor delays are involved
in neural transmission, muscle force generation and effector inertia. In partic—
ular, vestibular conscious perception of motion is strikingly slow as compared
to Visual, auditory or tactile perception (Barnett—Cowan, 2013). In general,
sensory—motor delays would result in motor responses too sluggish to be ef—
fective unless they were compensated by predictive components.

If there is a consensus about the existence of predictions about the effects of
gravity, the nature of these predictions is still controversial (Zago et al., 2008,
£9). The controversy revolves around the more general inverse problem of
perception, that is, how the brain can recover the external source of stimulation
and generate adequate responses starting from under—determined, ambiguous
sensory signals. For instance, although objects are accelerated by gravity at a
constant rate, the corresponding acceleration of the retinal image is not con—
stant at all, but is inversely related to the Viewing distance. In line of principle,
retinal motion information might be scaled by Viewing distance to estimate
target motion in world coordinates. However, Viewing distance is hard to es—
timate, especially when it is time—varying as in the case of an approaching
target, such as a projectile. In line of principle, eye vergence, accommodation,
stereodisparity and motion parallaX may contribute to estimates of Viewing
distance of target motion in 3D space, but these cues are ineffective when the
Figure 7 (Continued). downwards (leftmost column), or upwards (middle column), although
the responses were much less variable in the former than the latter case. In contrast, the re-
sponses for unidirectional motion along the circle (rightmost column) clustered Close to the
constant speed proﬁle. This ﬁgure is published in colour in the online version.

"
"20","20 F. Lacquaniti et al. /Multisens0ry Research (2015)

target is distant or when it is animated on a 2D Video display. Pictorial infor—
mation from the moving target or the background of the Visual scene also may
help recovering an environmental reference and scale (Distler et al., 2000).
However, there is no evidence that the brain keeps perceptual constancy of
gravitational acceleration at varying Viewing conditions. Moreover, percep—
tion and motor responses do not necessarily share a common neural estimate
of Viewing distance (Wei et al., 2003).

Different solutions to the inverse problem have been proposed. According
to the ecological theory of perception championed by Gibson (1979), sen—
sory stimuli derived from organism—environment interactions (‘affordances’)
are sufﬁcient to recover the external source of stimulation under natural con—
ditions, because the physical laws constrain a potentially under—determined
problem, excluding all solutions that are ecologically impossible and are there—
fore irrelevant to perception. However, there are intrinsic limitations in the
sensory signals that preclude perfect compensation of sensori—motor delays.
Thus, because the Visual system is essentially insensitive to target accelera—
tion over short time epochs (e.g., Brouwer et al., 2002; Calderone and Kaiser,
1989; Werkhoven et al., 1992), the timing of interception responses as well as
the perceptual judgment of elapsed time are often based on ﬁrst—order algo—
rithms including target position and velocity, but not acceleration (Kaiser and
Hecht, 1995; Port et al., 1997; Senot et al., 2003). Such ﬁrst—order algorithms
are Clearly inadequate to cope with the strong gravitational acceleration (see
Zago et al., 2008).

Purves et al. 52014) revisited the Gibsonian approach, and proposed that the
brain does not even try to solve the inverse problem, but simply links the fre—
quency of occurrence of biologically determined stimuli to useful perceptual
and behavioral responses without recovering real—world properties. However,
neither Gibson’s nor Purves’s hypotheses offer satisfactory accounts for the
observation that the same Visual stimuli can generate completely different re—
sponses depending on the cognitive context. Thus, subjects tend to respond
too early when a target descends at constant speed vertically when the target
is expected to move under the effects of earth’s gravity, while the same type of
target motion is intercepted at the right time if it is not expected to be subject
to gravity (Zago et al., 2004).

In contrast with the ecological theory, the constructivist theory posits that
sensory information is inherently ambiguous and insufﬁcient to solve the in—
verse problem, and must be augmented by making ‘unconscious inferences’
about the world, constructed on past experience (Helmholtz, 1925; SheEard,
£4). The hard version of constructivism assumes complementarity in the
correspondence between psychological structures and environmental struc—
tures (SheEard, 1984, $4). Accordingly, internal representations would mir—
ror the actual physical principles that govern the environment. For instance,

"
"21","Multisensory Research (2015) DOI:10.1163/22134808-00002471 21
neural anticipation of a gravitational motion would ideally be based on eX—
act Newton’s laws. However, because cognitive judgments Often appear to be
inconsistent from Newtonian mechanics, psychologists have suggested that
people’s intuitive physics is based on a set of shortcuts 0r heuristics rather
than realistic models of physics (e.g., McCloskey, 1983). Nevertheless, when
people’s responses are provided under naturalistic dynamic perceptual and ac—
tion contexts, they are Often in accord with physics as we reviewed in this
article.

Currently, the most plausible and general account of the experimental eVi—
dence reviewed in this article is provided by soft versions of the constructivist
theory that assume either approximate models of physics (Zago et al., 2008)
or exact models combined with noisy Observations (Sanbom et al., 2013).

Thus, probabilistic accounts have been proposed for both the estimate of
vertical orientation and that of time passage. With regards to the former,
Battaglia et al. 52013) validated a model that uses approximate, probabilistic
simulations of mechanics to make robust and fast inferences in complex nat—
ural scenes where crucial information is missing. One of their tasks involved
subjective judgments of stability under the perturbing inﬂuence of gravity of
Virtual towers of stacked blocks of bricks presented on a monitor. Their results
provided support to the idea that human judgments are driven by rich phys—
ical simulations. At the same time, the results supported the idea that these
simulations are probabilistic, by showing in some cases systematic deviations
of people’s judgments from true physics, as well as the existence of stabil—
ity illusions. The conceptual architecture of their model is reminiscent of that
of computer graphics engines that are now used in realistic Videogames. With
regards to estimates of time passage, Ahrens and Sahani (2011) argued that 0b—
serVed biases in perceived time may ultimately derive from an adaptive use of
stochastically evolving dynamic stimuli to help reﬁne estimates derived from
internal time—keeping mechanisms, essentially a process of Bayesian inference
based on expectations of Change in the natural environment.

Finally, we note that potentially common neural regions may be involved
in the weighting of multisensory cues for the perception of verticality and
for estimates of the timing of physical events affected by gravity, in parallel
with the observation that similar probabilistic models may account for both
temporal and spatial orientation estimates. Thus, functional neuroimaging and
trans—cranial magnetic stimulation have shown that several areas (such as the
posterior insula and supramarginal gyrus) of multisensory network at the junc—
tion of frontal—parieta1—temp0ra1 lobes engaged in the processing of timing
information for Visual stimuli congruent with the effects of gravity (1m
et al., 2008; IndOVina et al., 2005, w); Maffei et al., 2010, m; Miller
et al., 2008) also contribute to accurate perception of upright (Kheradmand et
al., 2013). Moreover, electrophysiological studies in the monkey showed that

"
"22","22 F. Lacquaniti et a1. /Multisens0ry Research (2015)

Purkinje cells in the caudal cerebellar vermis encode head tilt, reﬂecting an
estimate of the direction of gravity based on vestibular information (Laurens
et al., 2013). Functional neuroimaging in humans showed that the posterior
cerebellar vermis (a putative human homologue region of that studied in mon—
keys by Laurens et al., 2013) and vestibular nuclei are involved in combining
pictorial information with the internal model of gravity to extract gravitational
motion from Visual scenes (Miller et al., 2008). Overall, the neuroimaging
studies mentioned above (Indoyina et al., 2005, w); Maffei et al., 2010,
£5; Miller et al., 2008) show that the effects of gravity on Visual motion
are encoded in a highly distributed cortical—subcortical network. Several re—
gions of this network co—localize with the regions independently activated by
vestibular caloric stimuli (Indovina et al., 2005). These regions belong to the
multi—modal vestibular network that responds to Visual and neck propriocep—
tive stimuli, in addition to vestibular stimuli (Bense et al., 2001; Bottini et al.,
& 1). Lesions of vestibular cortex often lead to a tilt of SVV and rotational
vertigo/unsteadiness (Brandt and Dieterich, 1999), and conversely focal elec—
trical stimulation or epileptic discharges in these regions elicit sensations of
self—motion or altered gravity (Nguyen et al., 2009).

Although there is some evidence for the existence of common substrates
for the perception of verticality and for the estimate of timing of gravitational
motion, we cannot rule out the alternative possibility that these two sets of
estimates are processed in partially segregated pathways. In this vein, Ventre—
Dominey (2014) has recently argued for distinct speed and inertial processing
pathways in the vestibular cortex. According to this hypothesis, self—motion
speed would be mainly processed in a pathway linking MST with the vestibu—
lar nuclei, whereas integration of inertial motion for space perception would be
mainly processed in a pathway linking the parietal cortex with the vestibular
nuclei complex responsible for velocity storage integration.

In conclusion, we reviewed several pieces of evidence arguing that the brain
is endowed with mechanisms that exploit the effects of gravity to estimate
spatial orientation and time. These mechanisms are based on the combina—
tion of multisensory cues (Visual, vestibular, haptic, proprioceptive) and prior
assumptions about the orientation and effects of gravity. Overall, these mecha—
nisms provide rich physical simulations that rely on probabilistic information,
giving rise to either accurate performance or systematic deviations from true
physics, depending on the context.

Acknowledgements
Our work was supported by the Italian Ministry of Health (RC and RF—
10.057), Italian Ministry of University and Research (PRIN grant

"
"23","Multisensory Research (2015) DOI:10.1163/22134808-00002471 23
2010MEFNF7_002), and Italian Space Agency (CRUSOE, COREA, SLINK
and ARIANNA grants).

References

Ahrens, M. B. and Sahani, M. (2011). Observers eX}:_)10it stochastic models of sensogy Change
to he1]:_) judge the Eassage of time, Curr. Biol. 21, 200—206.

Angelaki, D. E. and Cullen, K. E. (2008 2. Vestibular system: the many facets of a multimodal
sense, Annu. Rev. Neurosci. 31, 125—150.

Angelaki, D., McHean, M., Dickman, J . D., Newlands, S. and Hess, B. (1999). Comgutation
of inertial motion: neural strategies to resolve ambiguous 0t01ith information, J. Neurosci.
19, 316—327.

Angelaki, D. E., Klier, E. M. and Snyder, L. H. (2009). A vestibular sensation: Erobabilistie
aggroaches t0 SEatial Eeroegtion, Neuron 64, 448—461.

AEEelle, S. (1972). PerceEtion and discrimination as a function of stimulus orientation: the
“obligue effect” in man and animals, Psychol. Bull. 78, 266—278.

Asch, S. E. and Witkin, H. A. (1948 2. Studies in S}:_)ace orientation. 1. PerceEtion 0f the ugright
With disglaced Visual ﬁelds, J. ExQ. Psychol. 38, 325—337.

Aubert, H. (1861). Eine scheinbare bedeutende Drehung V0n Objekten bei Neigung des K0}:_)fes
nach rechts Oder links, Arch. Path. Anat. Physiol/Virchows Arch. 20, 381—393.

Ball, K. and Sekuler, R. (1987). Direction-speciﬁc improvement in motion discrimination, Vi-
sion Res. 27, 953—965.

Barlow, H. B. (1959). Sensory mechanisms, the reduction of redundancy, and intelligence, in:
Proceedings of the National Physical Laboratog Sxmgosium, D. V. Blake and A. M. Uttley
(Eds), 1:312. 537—559. H. M. Stationary Ofﬁce, London, UK.

Barnett-Cowan, M. (2013). Vestibular Eeroegtion is slow: a review, Multisens. Res. 26, 387—
ﬂ

Barnett-Cowan, M. and Biilthoff, H. H. (2013). Human Bath navigation in a three-dimensional
world, Behav. Brain Sci. 36, 544—545.

Barnett-Cowan, M. and Harris, L. R. (2008). Perceived self—orientation in allocentric and ego-
centric sgace: effects of Visual and Ehysical tilt 0n saccadic and tactile measures, Brain Res.
1242, 231—243.

Barnett-Cowan, M., Fleming, R. W., Singh, M. and Biilthoff, H. H. (2011). Perceived Object
stability degends 0n multisensory estimates of gravity, PLoS One 6(4), e19289.

Barnett-Cowan, M., Meilinger, T., Vidal, M., Teufel, H. and Bijlthoff, H. H. (2012 2. MP1 Cyber-
Motion Simulator: imglementation Of a novel motion simulator to investigate multisensory
Bath integration in three dimensions, J. Vis. ExQ. May 10(63 2, e3436.

Barnett-Cowan, M., Jenkin, H. L., Dyde, R. T., Jenkin, M. R. and Harris, L. R. (2013 2. Asym-
metrical regresentation of body orientation, J. Vis. Feb. 1; 13(2): 3.

Battaglia, P. W., Hamrick, J . B. and Tenenbaum, J . B. (2013 2. Simulation as an engine of Ehys-
ical scene understanding, Proc. Natl Acad. Sci. USA 110, 18327—18332.

Baumgartner, T., SEeck, D., Wettstein, D., Masnari, 0., Beeli, G. and J éincke, L. (2008 2. Feeling
Eresent in arousing Virtual reality worlds: Qrefrontal brain regions differentially orchestrate
p_resence eXEerience in adults and Children, Front. Hum. Neurosci. 2, 8.

"
"24","24 F. Lacquaniti et a1. /Multisensory Research (2015)

Bense, S., SteEhan, T., Yousry, T. A., Brandt, T. and Dieterieh, M. (2001). Multisensory cortical
signal increases and decreases during vestibular galvanic stimulation (fMRI), J. Neuroghxs-
1'01. 85, 886—899.

Berthoz, A. (2000 2. The Brain ’3 Sense ofMovement. Harvard University Press, Cambridge, MA,
USNLondon, UK.

Bingham, G. P., Rosenblum, L. D. and Schmidt, R. C. (1995). Dynamics and the orientation
of kinematic forms in Visual event recognition, J. ExQ. Psycho]. Hum. Percegt. Perform. 21,
1473—1493.

Bischof, N. (1974). Optic—vestibular orientation to the vertical, in: Handbook ofSensory Phys-
iology, H. H. Kornhuber (Ed.), pp. 155—190. Springer, Berlin, Heidelberg, Germany/New
York, NY, USA.

Bortolami, S. B., Pierobon, A., DiZiO, P. and Laekner, J . R. (2006). Localization of the subjec-
tive vertical during r011, Bitch, and recumbent yaw body tilt, ExQ. Brain Res. 173, 364—373.

Boseo, G., Carrozzo, M. and Laeguaniti, F. (2008). Contributions of the human temgorogari-
etal junction and MT/V 5 —|— to the timing of interceEtion revealed by transcranial magnetic
stimulation, J. Neurosci. 28, 12071—12084.

Boseo, G., Delle Monaehe, S. and Laeguaniti, F. (2012). Catching What we can’t see: manual
interceEtion 0f occluded ﬂy-ball trajectories, PLoS One 7(11), e49381.

Bottini, G., Karnath, H. 0., Vallar, G., Sterzi, R., Frith, C. D., Fraekowiak, R. S. J . and Paulesu,
E. (2001). Cerebral regresentations for egocentric SEaCC. Funetional-anatomieal evidence
from calorie vestibular stimulation and neck Vibration, Brain 124, 1182—1196.

Bozzi, P. (1958). Analisi fenomenologiea del moto pendolare armonieo, Riv. Psicol. 52, 281—
302.

Brandt, T. and Dieterieh, M. (1999). The vestibular cortex. Its locations, functions, and disor-
ders, Ann. NY. Acad. Sci. 871, 293—312.

Brenner, E., Driesen, B. and Smeets, J . B. (2014). Precise timing When hitting falling balls,
Front. Hum. Neurosci. 8, 342.

Brouwer, A. M., Brenner, E. and Smeets, J . B. (2002). PereeEtion of acceleration With short
p_resentati0n times: can acceleration be used in intereeEtion? Percegt. Psychoghxs. 64, 1160—
L68-

Brown, S. W. (1995 2. Time, Change, and motion: the effects of stimulus movement on tem}:_)0ra1
p_eree}:_)ti0n, Percegt. Psychoghxs. 57, 105—116.

Buhusi, C. V. and Meek, W. H. (2005). What makes us tick? Functional and neural mechanisms
of interval timing, Nat. Rev. Neurosci. 6, 755—765.

Calderone, J . B. and Kaiser, M. K. (1989). Visual acceleration detection: effect of sign and
motion orientation, Percept. Psychophys. 45, 391—394.

Carrozzo, M., Moseatelli, A. and Laeguaniti, F. (2010 2. Tem}:_)0 rubato: animaey s]:_)eeds 112 time
in the brain, PLoS One 5(12), e15638.

Cesgui, B., d’Avella, A., Portone, A. and Laeguaniti, F. (2012 2. Catching a ball at the right time
and Qlaee: individual factors matter, PLoS One 7(2), e31770.

Chang, D. H. F. and Troje, N. F. (2009). Acceleration carries the local inversion effect in bio-
logical motion Eeroegtion, J. Vis. 9(1), 19, 1—17.

Chang, D. H., Harris, L. R. and Troje, N. F. (2010). Frames of reference for biological motion
and face Eeroegtion, J. Vis. 10(6 2, 22.

"
"25","Multisensory Research (2015) DOI:10.1163/22134808—00002471 25

Clemens, I. A. H., De Vrijer, M., Selen, L. P. J ., Van Gisbergen, J . A. M. and Medendorg, W. P.
(2011). Multisensory Qrocessing in SQatial orientation: an inverse Qrobabilistie aggroach,
J. Neurosci. 31, 5365—5377.

Clement, G. and Reschke, M. F. (2008 2. Neuroscience in Same. Syringer, New York, NY, USA.

D’Andola, M., Cesgui, B., Portone, A., Fernandez, L., Lacguaniti, F. and d’Avella, A. (2013).
SEatiotemgoral characteristics of muscle Eatterns for ball catching, Front. Comgut. Neurosci.
7, 107.

Davidson, P. R. and W01}:_)ert, D. M. (2005). Wideslgread access to Qredictive models in the motor
system: a short review, J. Neural Eng. 2, S313—S319.

De Haes, H. A. U. (1970). Stability of aQQarent vertical and ocular counter-torsion as a function
of lateral tilt, Percegt. Psychoghxs. 8, 137—142.

De Vrijer, M., Medendorg, W. P. and Van Gisbergen, J . A. M. (2008). Shared comgutational
mechanism for tilt comgensation accounts for biased verticality ]:_)erce}:_)ts in motion and Eat-
tern Vision, J. Neuroghxsiol. 99, 915—930.

De Winkel, K. N., Clement, G., Groen, E. L. and Werkhoven, P. J . (2012). The Qercegtion 0f
verticality in lunar and Martian gravity conditions, Neurosci. Lett. 529, 7—1 1.

De11e Monache, S., Lacguaniti, F. and B0300, G. (in Eress). Eye movements and manual inter-
ce}:_)ti0n of ballistic trajectories: effects of law of motion Qerturbations and occlusions, ExQ.
Brain Res.

Diaz, G., COOBCI‘, J ., Rothkolgf, C. and Hayhoe, M. (2013). Saccades to future ball location
reveal memory-based Erediction in a Virtual-reality interceEtion task, J. Vis. 13(1). Eii: 20.

Distler, H. K., Gegenfurtner, K. R., van Veen, H. A. and Hawken, M. J . (2000). Velocity con-
stancy in a Virtual reality environment, Percegtion 29, 1423—1435.

Dyde, R. T., Jenkin, M. R. and Harris, L. R. (2006). The subjective Visual vertical and the
Eeroegtual uQright, ExQ. Brain Res. 173, 612—622.

Eagleman, D. M. (2004). Time Qercegtion is distorted during slow motion sequences in movies,
J. 145.4(8), 491, 491a.

Eagleman, D. M. (2008 2. Human time Eeroegtion and its illusions, Curr. 02in. Neurobiol. 18,
131—136.

Eagleman, D. M., Tse, P. U., Buonomano, D. V., Janssen, P., Nobre, A. C. and Holcombe,
A. O. (2005). Time and the brain: how subjective time relates to neural time, J. Neurosci.
25, 10369—10371.

Fernandez, C. and Goldberg, J . M. g 1976 2. Physiology of Eerigheral neurons innervating 0t01ith
organs of the sguirrel monkey. I. Resgonse to static tilts and t0 long-duration centrifugal
force, J. Neuroghxsiol. 39, 970—984.

Fraisse, P. (1963). The Psychology of Time. Harper and ROW, New York, NY, USA.

Frick, A., Huber, S., Rei}:_)s, U. D. and Krist, H. (2005 2. Task—slgeciﬁc knowledge of the law of
Eendulum motion in Children and adults, Swiss J. Psychol. 64, 103—114.

Fuller, P. M. and Fuller, C. A. (2006). Genetic evidence for a neurovestibular inﬂuence on the
mammalian Circadian Eacemaker, J. Biol. Rhythms 21, 177—184.

Georgogoulos, A. P. (2002). Cognitive motor control: SEatial and temgoral aSECCtS, Curr. 02in.
Neurobiol. 12, 678—683.

Gibson, J . J . g 1952 2. The relation between Visual and Eostural determinants of the Ehenomenal
vertical, Psychol. Rev. 59, 370—375.

Gibson, J . J . (1979). The Ecological Aggroach to Visual Percegtion. Houghton Mifﬂin, Boston,
MA, USA.

"
"26","26 F. Lacquaniti et a1. /Multisensory Research (2015)

Gibson, J . J . and Mowrer, O. H. (1938 2. Determinants of the ]:_)erceived vertical and horizontal,
Psychol. Rev. 45, 300—323.

Glasauer, S. (1992). Interaction of semicircular canals and 0t01iths in the Qrocessing structure
of the subjective zenith, Ann. N. Y. Acad. Sci. 656, 847—849.

Glasauer, S. and Mittelstaedt, H. (1998). Percelgtion 0f sEatial orientation in microgravity, Brain
Res. Rev. 28, 185—193.

Gémez, J . and LéEez-Moliner, J . (2013 2. Synergies between 0}:_)tica1 and Ehysical variables in
intercthing Qarabolic targets, Front. Behav. Neurosci. 7, 46.

Grealy, M. A., Craig, C. M., Bourdin, C. and Coleman, S. G. (2004). Judging time intervals
using a model of QercegtuO-motor control, J. Cogn. Neurosci. 16, 1185—1195.

Haggard, P., Clark, S. and Kalogeras, J . (2002). Voluntary action and conscious awareness, Nat.
Neurosci. 5, 382—385.

Hagura, N., Kanai, R., Orgs, G. and Haggard, P. (2012). Ready steady 310W: ﬁction Eregaration
slows the subjective Eassage of time, Proc. Biol. Sci. 279, 4399—4406.

Hansen, B. C. and Essock, E. A. (2004). A horizontal bias in human Visual Erocessing 0f ori-
entation and its corresgondence t0 the structural comgonents of natural scenes, J. Vis. 4,
1044—1060.

Harris, L. R., Jenkin, M., Dyde, R. T. and Jenkin, H. (2011). Enhancing Visual cues to orienta-
tion: suggestions for SEaCC travelers and the elderly, Prog. Brain Res. 191, 133—142.

Harris, L. R., Jenkin, M. R. M. and Dyde, R. T. (2012). The perception of upright under lunar
gravity, J. Gravit. Physiol. 19, 9—16.

Harris, L. R., Her}:_)ers, R., Hofhammer, T. and J enkin, M. (2014). HOW much gravity is needed
to establish the Eeroegtual ugright? PLoS One 9( 9 2, e106207.

Helmholtz, H. L. F. (1925). The Perceptions of Vision. Physiological Optics, Vol. 111. Optical
Society Of America, Rochester, NY, USA.

Howard, 1. P. (1982). Human Visual Orientation. Wiley, New York, NY, USA.

Huber, S. and Krist, H. (2004 2. When is the ball going to hit the ground? Duration estimates, eye
movements, and mental imagery of Object motion, J. ExQ. Psycho]. Hum. Percegt. Perform.
30, 431—444.

Huron, D. B. (2006). Sweet Anticigation: Music and the Psychology of ExQectation. MIT Press,
Cambridge, MA, USA.

Indovina, I., Maffei, V., BOSCO, G., Zago, M., Macaluso, E. and Lacguaniti, F. (2005 2. Regresen-
tation of Visual gravitational motion in the human vestibular cortex, Science 308, 416—419.

Indovina, I., Maffei, V. and Lacguaniti, F. (2013a). Anticigating the effects of Visual gravity dur-
ing simulated self—motion: estimates of time-tO-Qassage along vertical and horizontal Baths,
ExQ. Brain Res. 229, 579—586.

Indovina, I., Maffei, V., Pauwels, K., Macaluso, E., Orban, G. A. and Lacguaniti, F. (2013b).
Simulated self—motion in a Visual gravity ﬁeld: sensitivity to vertical and horizontal heading
in the human brain, Neuroimage 71, 114—124.

J enkin, H. L., J enkin, M. R., Dyde, R. T. and Harris, L. R. (2004). ShaQe-from-shading degends
on Visual, gravitational, and body-Orientation cues, Percegtion 33, 1453—1461.

Jenkin, M. R., Dyde, R. T., Jenkin, H. L., Zacher, J . E. and Harris, L. R. (2011). PerceEtual
ugright: the relative effectiveness of dynamic and static images under different gravity states,
Seeing Perceiving 24, 53—64.

Kaiser, M. K. and Hecht, H. (1995). Time-tO-Qassage judgments in nonconstant 0}:_)tiea1 ﬂow
ﬁelds, Percegt. PSXChOQhXS. 57, 817—825.

"
"27","Multisensory Research (2015) DOI:10.1163/22134808-00002471 27

Kanai, R., Paffen, C. L., Hogendoorn, H. and Verstraten, F. A. (2006 2. Time dilation in dynamic
Visual disglay, J. Vis. 6, 1421—1430.

Kaneko, S. and Murakami, I. (2009). Perceived duration of Visual motion increases with S}:_)eed,
J. Vis. 9, 1—12.

Kagtein, R. G. and Van Gisbergen, J . A. (2004). Intergretation Of a discontinuity in the sense of
verticality at large body tilt, J. Neuroghxsiol. 91, 2205—2214.

Kheradmand, A., Lasker, A. and Zee, D. S. (in Eress 2. Transcranial magnetic stimulation
(TMS) 0f the sugramarginal gyrus: a window to Qercegtion 0f uQright, Cereb. Cortex.
DOI:10.1093/Cereor/bht267.

Klatzkx, R. L. (1998). Allocentric and egocentric SQatial regresentations: deﬁnitions, distinc-
tions, and interconnections, in: SQatial Cognition, C. Freksa, C. Habel and K. F. Wender
(Eds), 1:39. 1—17. Syringer, BerlirﬂHeidelberg, Germany.

K0fﬂ<a, K. (1935). Gestalt Psychology. Harcourt Brace, New York, NY, USA.

Kéhler, W. (1940). Dynamics in Psycholo g2. Liveright, New York, NY, USA.

Kushiro, K., Taga, G. and Watanabe, H. (2007). Frame of reference for Visual Eeroegtion in
young infants during Change Of body Qosition, ExQ. Brain Res. 183, 523—529.

La Scaleia, B., Lacguaniti, F. and Zago, M. (2014a). Neural extragolation of motion for a ball
rolling down an inclined Blane, PLOS One 95 6 2, e99837.

La Scaleia, B., Zago, M., Moscatelli, A., Lacguaniti, F. and Viviani, P. (2014b 2. Imglied dynam-
ics biases the Visual Eeroegtion of velocity, PLoS One 9g 3 2, e93020.

Lackner, J . R. and DiZiO, P. (2005 2. Vestibular, Erogriocegtive, and ha}:_)tic contributions to 39a-
tial orientation, Annu. Rev. Psychol. 56, 115—147.

Lacquaniti, F. (1997). Frames of reference in sensorimotor coordination, in: Handbook ofNeu-
ropsychology, F. B011er and J . Grafman (Eds), V01. 11, pp. 27—64. Elsevier, Amsterdam.
Lacguaniti, F. and Maioli, C. (1989a). Adagtation t0 suggression of Visual information during

catching, J. Neurosci. 9, 149—159.

Lacguaniti, F. and Maioli, C. g 1989b 2. The role of Eregaration in tuning anticigatory and reﬂex
resgonses during catching, J. Neurosci. 9, 134—148.

Lacguaniti, F., Carrozzo, M. and Borghese, N. A. (1993 2. The role of Vision in tuning antic-
iQatorX motor resgonses 0f the limbs, in: Multisensog Control of Movement, A. Berthoz,
C. Gielen, V. Henn, K. P. Hoffmann, M. Imbert, F. Lacguaniti and A. RoucouX (Eds 2,
91:3. 379—393. Oxford University Press, Oxford, UK.

Lacguaniti, F., BOSCO, G., Indovina, 1., La Scaleia, B., Maffei, V., Moscatelli, A. and Zago, M.
(2013). Visual gravitational motion and the vestibular system in humans, Front. Int. Neu-
rosci. 7, 101.

Lacguaniti, F., BOSCO, G., Gravano, S., Indovina, 1., La Scaleia, B., Maffei, V. and Zago, M.
(2014a 2. Multisensory integration and internal models for sensing gravity effects in Erimates,
Biomed Res. Int. 2014, 615854.

Lacguaniti, F., Carrozzo, M., d’Avella, A., La Scaleia, B., Moscatelli, A. and Zago, M. (2014b).
How long did it last? You would better ask a human, Front. Neurorobot. 8, 2.

Large, E. W. (2008 2. Resonating to musical rhythm: theory and eXEeriment, in: The Psycholo g
of Time, S. Grondin (Ed. 2, 1:312. 189—231. Emerald, Bingley, UK.

Laurens, J ., Meng, H. and Angelaki, D. E. (2013 2. Neural regresentation of orientation relative
to gravity in the macague cerebellum, Neuron 80, 1508—1518.

Le Séac’h, A. B., Senot, P. and McIntyre, J . (2010). Egocentric and allocentric reference frames
for catching a falling Object, ExQ. Brain Res. 201, 653—662.

"
"28","28 F. Lacquaniti et a1. /Multisensory Research (2015)

Lee, D. N. (1998 2. Guiding movement by cougling taus, Ecol. Psychol. 10, 221—250.

Lewis, P. A. and Miall, R. C. (2003 2. Distinct systems for automatic and cognitively controlled
time measurement: evidence from neuroimaging, Curr. Ogin. Neurobiol. 13, 250—255.

Lohmaier, J . S. and Mast, F. W. (2007). The Thatcher illusion: rotating the Viewer instead of the
Eicture, Percegtion 36, 537—546.

L0]:_)ez, C., Bachofner, C., Mercier, M. and Blanke, O. (2009). Gravity and Observer’s body
orientation inﬂuence the Visual Eeroegtion of human body Eostures, J. Vis. 9, 1, 1—14.

Luck, G. and Sloboda, J . A. (2007). An investigation of musicians’ synchronization With tradi-
tional conducting beat patterns, Music Perform. Res. 1, 26—46.

MaeNeilage, P. R., Banks, M. S., Berger, D. R. and Bulthoff, H. H. (2007 2. A Bayesian model
of the disambiguation 0f gravitoinertial force by Visual cues, ExQ. Brain Res. 179, 263—290.

Maffei, V., Macaluso, E., Indovina, 1., Orban, G. and Lacguaniti, F. (2010). Processing of tar-
gets in smooth or aEEarent motion along the vertical in the human brain: an MRI study,
J. Neuroghxsiol. 103, 360—370.

Maffei, V., Indovina, 1., Macaluso, E., Ivanenko, Y. P., Orban, G. and Lacguaniti, F. (2015 2. Vi-
sual gravity cues in the intergretation of biological movements: neural correlates in humans,
Neuroimage 104, 221—230.

Mann, C. W., Berry, N. H. B. and Daitterive, H. J . (1949). The perception of the vertical. 1.
Visual and non-labyrinthine cues, J. Exp. Psychol. 39, 538—547.

Mast, F. and J archow, T. (1996). Perceived body Eosition and the Visual horizontal, Brain Res.
Bull. 40, 393—397.

Matthews, W. J . (2011). HOW d0 Changes in s]:_)eed affect the Qercegtion of duration? J. ExQ.
Psychol. Hum. Percegt. Perform. 37, 1617—1627.

Mauk, M. D. and Buonomano, D. V. (2004). The neural basis of tem}:_)0ra1 Erocessing, Annu.
Rev. Neurosci. 27, 307—340.

McCloskey, M. (1983). Intuitive physics, Sci. Am. 284, 114—123.

McIntyre, J ., Zago, M., Berthoz, A. and Lacguaniti, F. (2001). Does the brain model Newton’s
laws? Nat. Neurosci. 4, 693—694.

McIntyre, J ., Senot, P., Prevost, P., Zago, M., Lacguaniti, F. and Berthoz, A. (2003 2. The use Of
on-line Qercegtual invariants versus cognitive internal models for the Qredictive control of
movement and action, in: Proc. First Int. IEEE EMBS Cont. Neural Eng, CaEri, 1:312. 438—
ﬂ

Merchant, H., Harrington, D. L. and Meek, W. H. (2013 2. Neural basis of the Eeroegtion and
estimation of time, Annu. Rev. Neurosci. 36, 313—336.

Merfeld, D., Zugan, L. and Peterka, R. (1999). Humans use internal models to estimate gravity
and linear acceleration, Nature 398, 615—618.

Mijatovié, A., La Scaleia, B., Mercuri, N., Lacquaniti, F. and Zago, M. (2014). Familiar trajec-
tories facilitate the interpretation of physical forces When intercepting a moving target, Exp.
Brain Res. 232, 3803—3811.

Miller, W. L., Maffei, V., Boseo, G., 10321, M., Zago, M., Macaluso, E. and Lacquaniti, F. (2008).
Vestibular nuclei and cerebellum put Visual gravitational motion in context, J Neurophysiol.
99, 1969—1982.

Mittelstaedt, H. (1983). A new solution to the Emblem 0f the subjective vertical, Naturwis-
senSChaften 70, 272—281.

Moore, J . W. and Obhi, S. S. (2012). Intentional binding and the sense of agency: a review,
Conscious Cogn. 21, 546—561.

"
"29","Multisensory Research (2015) DOI:10.1163/22134808-00002471 29

Morgenstern, Y., Murray, R. F. and Harris, L. R. (2011). The human Visual system’s assumgtion
that light comes from above is weak, Proc. Natl Acad. Sci. USA 108, 12551—12553.

Moscatelli, A. and Lacguaniti, F. (2011). The weight of time: gravitational force enhances dis-
crimination of Visual motion duration, J. Vis. 11(4), Qii: 5.

Nesti, A., Barnett-Cowan, M., Macneilage, P. R. and Biilthoff, H. H. (2014). Human sensitivity
to vertical self—motion, ExQ. Brain Res. 232, 303—314.

Nguyen, D. K., Nguyen, D. B., Malak, R., LerouX, J . M., Carmant, L., Saint-Hilaire, J . M., Gi-
ard, N., Cossette, P. and Bouthillier, A. (2009 2. Revisiting the role of the insula in refractogy
Bartial eQiIeQSX, EQileQSia 50, 510—520.

Orgs, G., Kirsch, L. and Haggard, P. (2013). Time Qercegtion during aQQarent biological motion
reﬂects subjective S}:_)eed of movement, not Objective rate of Visual stimulation, ExQ. Brain
Res. 227, 223—229.

Paillard, J . g 1991 2. Motor and regresentational framing of sgace, in: Brain and SQace, J . Paillard
(Ed. 2, 1:312. 163—182. Oxford University Press, New York, NY, USA.

Pavlova, M. and SOkOlOV, A. (2000). Orientation sgeciﬁcitx in biological motion Eeroegtion,
Percegt. Psychoghxs. 62, 889—899.

Pettorossi, V. E., Bambagioni, D., Bronstein, A. M. and Gresty, M. A. (1998). Assessment of
the Eeroegtion 0f verticality and horizontality With self—Eaced saccades, ExQ. Brain Res. 121,
46—50.

Pittenger, J . B. (1990). Detection of Violations of the law of Eendulum motion: Observers’ sen-
sitivity t0 the relation between Qeriod and length, Ecol. Psycho]. 2, 55—81.

Port, N. L., Lee, D., Dassonville, P. and Georgogoulos, A. P. (1997). Manual intercelgtion of
moving targets. 1. Performance and movement initiation, ExQ. Brain Res. 116, 406—420.
Preuss, N., Harris, L. R. and Mast, F. W. (2013). Allocentric Visual cues inﬂuence mental trans-

formation of bodies, J. Vis. 13g122, 14.

Purves, D., Monson, B. B., Sundararajan, J . and Wojtach, W. T. (2014). HOW biological Vision
succeeds in the Ehysical world, Proc. Natl Acad. Sci. USA 111, 4750—4755.

Reed, C. L., Stone, V., Bozova, S. and Tanaka, J . (2003 2. The body inversion effect, Psychol.
Sci. 14, 302—308.

Runeson, S. (1974). Constant velocity — not ]:_)erceived as such, Psychol. Res. 37, 3—23.

Sanborn, A. N., Mansinghka, V. K. and Grifﬁths, T. L. (2013). Reconciling intuitive Ehysics
and Newtonian mechanics for colliding Objects, Psychol. Rev. 120, 411—437.

Senot, P., Prevost, P. and McIntyre, J . (2003). Estimating time to contact and imgact velocity
When catching an accelerating Object With the hand, J. ExQ. Psycho]. Hum. Percegt. Perform.
29, 219—237.

Senot, P., Zago, M., Lacguaniti, F. and McIntyre, J . (2005 2. Anticigating the effects of gravity
when intercthing moving Objects: differentiating u}:_) and down based on non-Visual cues,
J. Neuroghxsiol. 94, 4471—4480.

Senot, P., Zago, M., Le Séac’h, A., Zaoui, M., Berthoz, A., Lacguaniti, F. and McIntyre, J .
(2012). When u}:_) is down in 0g: how gravity sensing affects the timing of interceEtive ac-
tions, J. Neurosci. 32, 1969—1973.

SheEard, R. N. (1984). Ecological constraints on internal regresentations: resonant kinematics
of Bereeiving, imagining, thinking, and dreaming, Psychol. Rev. 91, 417—447.

Shegard, R. N. (1994). Percegtual-cognitive universals as reﬂections of the world, Psychon.
Bull. Rev. 1, 2—28.

"
"30","30 F. Lacquaniti et a1. /Multisensory Research (2015)

Shigley, T. F. (2003 2. The effect of Object and event orientation on Eeroegtion of biological
motion, Psychol. Sci. 14, 377—380.

Simoncelli, E. P. and Olshausen, B. A. (2001). Natural image statistics and neural regresenta-
tion, Annu. Rev. Neurosci. 24, 1193—1216.

Su, Y. H. (2014 2. Peak velocity as a cue in audiovisual synchrony Eeroegtion of rhythmic stimuli,
Cognition 131, 330—344.

Sumi, S. ( 1984 2. UEside-down Eresentation 0f the J Ohansson moving light-sgot Eattern, Perceg-
tion 13, 283—286.

Thomgson, P. (1980). Margaret Thatcher: a new illusion, Percegtion 9, 483—484.

Troje, N. F. (2003). Reference frames for orientation anisotrogies in face recognition and
biological-motion Eeroegtion, Percegtion 32, 201—210.

Troje, N. F. and Westhoff, C. (2006). The inversion effect in biological motion Eeroegtion:
evidence for a “life detector”? Curr. Biol. 16, 821—824.

Ventre-Dominey, J . (2014). Vestibular function in the temlgoral and Qarietal cortex: distinct ve-
locity and inertial Erocessing Eathways, Front. Integr. Neurosci. 8, 53.

Vingerhoets, R. A. A., De Vrijer, M., Van Gisbergen, J . A. M. and Medendorp, W. P. (2009).
Fusion of Visual and vestibular tilt cues in the perception of Visual vertical, J. Neurophysiol.
101, 1321—1333.

Wei, M., DeAngelis, G. C. and Angelaki, D. E. (2003). D0 Visual cues contribute to the neural
estimate of Viewing distance used by the oculomotor system? J. Neurosci. 23, 8340—8350.

Werkhoven, P., SniEEe, H. P. and T0et, A. ( 1992 2. Visual Erocessing 0f 0}:_)tic acceleration, Vision
Res. 32, 2313—2329.

Yin, R. K. (1969 2. Looking at uEside-down faces, J. ExQ. Psychol. 81, 141—145.

Zago, M. and Lacguaniti, F. (2005a). Cognitive, Qercegtual and action-oriented regresentations
of falling Objects, Neurogsxchologia 43, 178—188.

Zago, M. and Lacguaniti, F. (2005b). Internal model of gravity for hand intercelgtion: Qarametric
adagtation t0 zero-gravity Visual targets on Earth, J. Neuroghxsiol. 94, 1346—1357.

Zago, M. and Lacguaniti, F. (20050 2. Visual Eeroegtion and interceEtion of falling Objects: a re-
View Of evidence for an internal model of gravity, J. Neural Eng. 2, S198—S208.

Zago, M., BOSCO, G., Maffei, V., Iosa, M., Ivanenko, Y. P. and Lacguaniti, F. (2004). Internal
models of target motion: eX}:_)ected dynamics overrides measured kinematics in timing man-
ual intercelgtions, J. Neuroghxsiol. 91, 1620—1634.

Zago, M., BOSCO, G., Maffei, V., Iosa, M., Ivanenko, Y. P. and Lacguaniti, F. (2005 2. Fast adaEta-
tion of the internal model of gravity for manual intercelgtions: evidence for event-degendent
learning, J. Neuroghxsiol. 93, 1055—1068.

Zago, M., McIntyre, J ., Senot, P. and Lacguaniti, F. (2008). Internal models and Erediction of
Visual gravitational motion, Vision Res. 48, 1532—1538.

Zago, M., McIntyre, J ., Senot, P. and Lacguaniti, F. (2009). VisuO-motor coordination and in-
ternal models for Object intercelgtion, ExQ. Brain Res. 192, 571—604.

Zago, M., Carrozzo, M., Moscatelli, A. and Lacquaniti, F. (2011a). Time, Observation, move-
ment, Cogn. Crit. 4, 61—86.

Zago, M., La Scaleia, B., Miller, W. L. and Lacguaniti, F. (2011b). Coherence of structural
Visual cues and Qictorial gravity Eaves the way for intercthive actions, J. Vis. 11(10), 13.
Zaidel, A., Ma, W. J . and Angelaki, D. E. (2013). SuQerVised calibration relies on the multisen-

sory ]:_)erce}:_)t, Neuron 80, 1544—1557.
All in-text references underlined in blue are linked to publications on ResearchGate, letting you access and res

"

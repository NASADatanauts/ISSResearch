"","x"
"1","Vision Research 49 (2009) 2131—2139
5;*/ Contents lists available at ScienceDirect FY3333?)
22 2,2) V151on Research -
- 2.282218...
ELSEVIER journal homepage: www.elsevier.com/|ocate/visres 0-9.3...
—
How long do 1ntr1n51c and extr1n51c Visual cues take to exert their effect
on the perceptual upright?
Bahar Haji—Khamneh *, Laurence R. Harris
Dept. Psychology, York University, 4700 Keele St, Toronto, ON, Canada M3] 1P3
ARTICLE INFO ABSTRACT
ArtiCle hiSIOU/I We determined the amount of time it took for intrinsic and extrinsic visual cues to determine the percep—
RECEiVEd 10 OCtOber 2008 tual upright. The perceptual upright was measured using a probe, the identity of which depended on its
Received in rEViSEd form 14 April 2009 perceived orientation (the Oriented Character Recognition Test). A visual background that ﬁlled the ﬁeld
of view and contained both intrinsic and extrinsic cues was presented in different orientations and for
— presentation times of between 50 and 500 ms followed by a mask. The contribution of each class of
Keywords: . cue was identiﬁed by exploiting their different degrees of ambiguity. Intrinsic cues include scene struc—
Or1entat10n percept10n . . . . . . . . .
Scene perception ture (e.g., walls, ﬂoor and ceiling of an indoor scene) which indicates four potential up directions, and the
Object perception horizon which indicates two poss1b111t1es. Extr1ns1c cues, which rely oniinformation notiin the image such
Visual frame as a surface acting as a support structure for an object, s1gnal the direction of up unambiguously. The con—
Horizon tribution of each class of visual cue could thus be identiﬁed from the number of cycles its effect showed
as the background was presented in all orientations round the clock. While the more high—level extrinsic
cues to up exerted a larger inﬂuence on the perceptual upright than the intrinsic cues, the magnitude of
each cue’s effect increased with presentation time at approximately the same rate with a time constant of
about 60 ms. This ﬁnding poses a challenge for bottom—up theories of scene perception and suggests that
low—level and high—level information are processed in parallel at least insofar as they indicate orientation.
© 2009 Elsevier Ltd. All rights reserved.
1. Introduction likely both be inﬂuenced to the same extent by background scene
orientation, the canonical orientation is derived from reaction time
Vision tells us about the identity of objects (‘seeing’) but also data whereas the PU is derived from a character recognition task.
carries proprioceptive information about the body’s orientation The perceptual upright is derived from a combination of visual
relative to the world. Orientation is fundamental to perception and vestibular cues, together with an internal representation of
and the recognition of objects depends on their orientation. The the orientation of the body (Asch 82 Witkin, 1948a; Dyde et al.,
perceived direction of ‘up’ has conventionally been measured using 2006; Mittelstaedt, 1986, 1999). Here we investigate speciﬁcally
the subjective visual vertical (e.g., Mittelstaedt, 1983). However, the contribution of the visual cue to the perceptual upright.
the orientation at which objects appear upright (the perceptual up— A typical scene contains both intrinsic and extrinsic visual cues
right) is not always the same as the orientation of the subjective to orientation. The overall frame or structure of the scene (ﬂoor or
visual vertical because the perceptual upright is more heavily ground plane, walls, ceiling or sky) and the orientation of the hori—
inﬂuenced by orientation of the visual background. Dyde, Jenkin, zon (even if not directly visible) are intrinsic to a scene. By contrast,
and Harris (2006) deﬁne the perceptual upright (PU) as being the the spatial—relationships between and within objects (that a table
orientation at which objects are recognized as being “the right can act as a support surface for an object; that a lampshade is at
way up”. The right way up is the orientation at which objects are the top of a lamp standard) are not intrinsic to scenes and have
most readily and accurately identiﬁed and is fundamental to our to be learned through familiarity with statistical regularities in
ability to interact with the environment. The perceptual upright the environment (Schwarzkopf 82 Kourtzi, 2008) and an internali—
is conceptually distinct from the ‘canonical orientation’ which de— zation of the laws of physics (McIntyre, Zago, Berthoz, 82 Lacquaniti,
ﬁnes ‘the right way up’ as the orientation at which objects are most 2001). These learned relationships constitute an axis of polarity
accurately and speedily recognized (see for e.g., Jolicoeur, 1985; that does not change when the overall scene changes in orienta—
McMullen 82 Jolicoeur, 1992). While the perceptual upright and tion. Such extrinsic cues will be referred to as polarizing cues.
the ‘canonical orientation’ are closely related concepts, and would The knowledge that light comes from above (Mamassian 82
Goutcher, 2001; Ramachandran, 1988) can also be used to specify
mending author_ Fax: +1 416 736 5814 the orientation of an object or scene using shading and shadows.
E-mail address: bahar.haji@gmail.com (B. Haji—Khamneh). The interpretation of this cue can be altered by experience suggesting
0042—6989/$ — see front matter © 2009 Elsevier Ltd. All rights reserved.
doi:10.1016/j.visres.2009.06.003

"
"2","2132 B. Haji—Khamneh, LR. Harris/ Vision Research 49 (2009) 2131—2139

that the light cue is also at least partially extrinsic (Adams, Graf, 82 cues and should take longer. Conversely, if low-level and high-level
Ernst, 2004). Whether intrinsic and extrinsic cues are processed by information were processed in parallel, we would expect no differ-
the same or different mechanisms is unknown. ences in the time course of intrinsic and extrinsic cues.

Intrinsic and extrinsic cues both contribute to determining the To test these hypotheses we used the Oriented CHAracter Rec-
PU. However, as Fig. 1 shows, some of these cues have different de- ognition Test (OCHART) (Dyde et al., 2006) which exploits the no-
grees of ambiguity and indicate more than one direction of up. The tion that the letters ‘p’ and ‘d’ rely on their orientation for their
fact that different cues are differentially ambiguous can be used to identity. By identifying the orientation at which the letter’s iden-
identify their contributions in a given scene. The intrinsic cue that tity is least certain (i.e., when either identify is equally likely to
comes from the structure of a room provides four potential direc- be perceived) we can obtain an estimate of the orientation at
tions of up: as the scene is rotated, each of these directions aligns which its orientation is most certain: the perceptual upright. The
with gravity every 900 of rotation. Likewise, the line specifying the inﬂuence of the orientation of the visual background was obtained
elevation of the horizon simultaneously indicates two directions of by repeating OCHART with the background at different orienta-
upright separated by 180°. In contrast to these ambiguous intrinsic tions. Each background was presented for a ﬁxed period of time be-
cues, extrinsic cues specify a unique direction of up. Each of these tween 50 and 500 ms followed immediately by a pattern mask that
cues is able to inﬂuence the orientation of the PU. Thus when a limited the processing time to the presentation duration.
scene ﬁlling the visual ﬁeld is presented at all orientations, the ef-
fect induced by the three classes of visual components within it 2 M

. . . . . ethods
can be d1st1ngu1shed by the number of cycles of shift of the percep-
tual upright that the tilted scene induces: the effect of the frame 2 1 S .
. . . . . ubjects
cues w111 complete four cycles, the horizon’s effect w111 complete
two and extrinsic cues will always indicate a unique direction. Three females and ﬁve males between the ages of 24 and 45

Whlle much 15 known about various properties Of the global participated in these experiments.All observers had normal or cor-
context such as color (Oliva 82 Schyns, 2000; Steeves Et al., 2004) rected-to-normal vision. All observers gave informed consent as
and spatial frequency (ROUSSEIEt’ Joubert, 82 Fabre—Thorpe, 2.005)’ required by the Ethics Guidelines of York University which com-
relatively httle 15 known about the inﬂuence Of th? orientation Of plies with the 1964 Declaration of Helsinki. Six of the participants
the global come?“ on the perception Of SElf and ObJECt orientation were volunteers and the other two were compensated at a rate of
(Rousselet, Mace, 82 Fabre—Thorpe, 2003; Vuong, Hof, Bulthoff, 82 $10 . All t' . t t 1 t . 11 . t

. . . per sessmn. par 1c1pan s oo< par in a experimen s.
Thornton, 2006). Extracting the gist of a scene can be done in less
than 150 ms (Hegde, 2008) but is the time it takes to extract a gist
comparable to the time it takes for a scene to exert an inﬂuence on 2-2- Apparatus
the perception of objects within it? Here we measured the time
course with which each class of cue present in the scene exerted Stimuli were presented on a 21 111- Dell P1110 Trinitron monitor
its effect, expecting that differential processing systems would be With a resolution 0f 28-3 pixels/cm and a mean luminance 0f
reﬂected in different amounts of time needed for each type of 43-15 Cd/mz at a refresh rate 0f120HZ (i.e., 8-33 ms/frame). Stim-
cue to exert its effect. If higher-level extrinsic polarizing cues re- Uh were composed one frame at a time and presented using
quire more semantic and spatial processing than relatively low-le- Psyscope 1-2-5 (Cohen, MacWhinney, Flatt, 82 PFOVOSt, 1993?
vel frame and horizon cues, then we might expect that such cues MacWhinney, Cohen, 82 PFOVOSt, 1997)- Because the timing 0f the
would exert their effect at a later stage than low-level intrinsic stimulus and mask presentation on the computer screen W35
0° 90° 180° 270°
extrinsic b \ :39 '- D {5 “
polarized ' _ V ' Q 7 ’°
cues .1 - ' H ' <32)
intrinsic 1% “\ ' 7-
horizon , - V L t ' 8 J: ’ '°.
cue =3 ‘ r ,—
intrinsic _
frame I I I
cue , _
Fig. 1. A visual scene contains several cues to orientation including high—level extrinsic polarizing cues (highlighted in the top row) and low—level intrinsic cues from the
horizon and visual frame (highlighted in the middle and bottom rows, respectively). When the picture is rotated through 360°, the direction of up speciﬁed by the polarizing
cues rotates through one cycle (top row); the direction speciﬁed by the horizon cue rotates two cycles (middle row) and the direction indicated by the frame cue (the square
formed by the edges of the walls and the ﬂoor and ceiling) rotates through four cycles (bottom row).

"
"3","B. Haji—Khamneh, L.R. Harris/ Vision Research 49 (2009) 2131—2139 2133
critical for this experiment we veriﬁed the timing of the stimuli constant, the same background photograph was used throughout.
carefully. Stimuli were presented for periods of time that were Any possible adaptation effects on the PU were assessed by com—
multiples of the frame duration and this was conﬁrmed using a paring data taken from the ﬁrst half of the data collection period
light—sensitive diode pointing at the screen. The screen was viewed with those taken in the second half.
at a distance of 25 cm through a black circular shroud that ob—
scured peripheral vision and that reduced the viewing area to a cir— 2.5. Procedure
cle subtending 28.5° of visual arc (Fig. 2).

Participants were instructed to identify the probe symbol as a
2.3. Test for perceptual upright ‘cl’ or a ‘p’ using the left and right buttons respectively on a game
pad. They were seated at a desk with their heads ﬁrmly positioned
The Oriented CHAracter Recognition Test (OCHART) technique against the circular tunnel approximately 25 cm from the com—
exploits the fact that the perceived identities of some objects de— puter screen (Fig. 2). Participants pressed any button on the key—
pend solely on their orientation (Dyde et al., 2006). The probe we board to start the experiment. At the start of each trial a 045°
used was the ambiguous character 0.. The character subtended ﬁxation point appeared against a grey background and stayed on
approximately 3.1° >< 1.9° of visual arc. Its perceived identity as a for 100 ms (12 frames) after which a probe/background stimulus
‘p’ or ‘cl’ is based exclusively on its orientation. combination was presented for either 6, 9, 18 and 60 frames. The
The method of constant stimuli was used to ﬁnd the two orienta— probe/background stimulus was followed immediately by a struc—
tions where the characterwas equally likely to be perceived as a ‘p’ or ture mask for 100 ms (12 frames). The mask was followed by a grey
a ‘cl’. The character was presented six times at 24 different orienta— screen at which time observers pressed the button to indicate the
tions spanning the range from 0° to 345° in 15° increments. The perceived identity of the symbol (‘p’ or ‘d’). After the participant re—
bisector of the two orientations at which the character was maxi— sponded, the ﬁxation point came on again and the next trial com—
mally ambiguous was taken as the orientation at which its identity menced. The sequence is summarized in Fig. 3.
was maximally certain and deﬁned as the perceptual upright.
2.6. Calculating the perceptual upright
2.4. Background stimuli
The percentage of times the symbol was identiﬁed as a ‘p’ was
The character probe was superimposed on a 285° circular back— plotted as a function of the probe orientation for each background
ground picture which was a colored photograph of a scene that orientation and presentation time. An example is shown in Fig. 4.
was rich in intrinsic and extrinsic visual cues specifying up (insert Two cumulative Gaussian functions were ﬁtted to the participants’
to Fig. 3). Since scenes with man—made structures include more responses to determine each of p—d and d—p transition orienta—
vertical lines and hence stronger intrinsic cues than natural scenes tions. The cumulative Gaussians were deﬁned as:
(Joubert, Rousselet, Fize, 82 Fabre—Thorpe, 2007) we chose a photo— 100
graph that was taken indoors. The background image was pre— y = m% (1)
sented at 16 orientations spaced equally around the clock (i.e., in
steps of 225°). Thus there were 408 (16 x 24) probe/background where x0 corresponds to the 50% point and b is the standard devia—
combinations which were each presented six times in a random— tiOh- The 50% 130th corresponds to the orientation 0f the probe at
ized order with presentation times of 50, 75, 150 and 500 ms (6, which either interpretation was equally likely 1.6., the ‘transition
9, 18 and 60 frames, respectively) resulting in a total of 9,216 (16 orientation’. The orientation midway between the P-d and d—P
backgrounds x 24 probe orientations x 4 presentation times x 6 transition angles W35 taken 35 the PU- 1n the example Shown in
repetitions) presentations. These were completed in six blocks of Fig. 4 thiS iS at 2-1""- The mean 0f the standard deviations 0f each
1536 trials each. Each block was approximately 1 h long and the of the two cumulative Gaussians was taken as the standard devia—
participants were allowed to take breaks. No feedback was given. tiOh 0f the observer’s response in each testing C0Dditi0h-
In order to keep the relative amount of intrinsic and extrinsic cues
2.7. Testing the time it took to identify the character probe
5 To establish that the probe could be identiﬁed at the different
presentation times used in this study we measured identiﬁcation
_- . I performance for a range of presentation times. Participants sat in
‘ - ° ,. ‘ the equipment as for the experiment proper (Section 2.5) and
f ~ r viewed the ﬁxation point. They were then shown the probe against
_ ' , .. the neutral grey background in either the ‘p’ or ‘cl’ orientation for
' ,4 ’ I between 2 and 9 frames (16.7—75 ms) followed by a structure
' ‘ "" J , @555: mask for 100 ms. Participants were asked to identify the letter
: _ ' NW1""!!! using the left and right buttons on the game pad. The next trial
""' commenced immediately after they responded. Ten ‘p’s and 10
\ ""Le... ‘d’s were presented at each of the eight timing conditions resulting
: ’ _..‘-.. “' ‘ in 160 (20 x 8) trials in total. The presentation of all stimuli was
. . g . - ~ ‘ t V "" randomized. No feedback was given. This phase of the experiment
( \ M ‘ was completed in approximately 5 min.
, . ‘5
. e 2.8. Convention
. . #552” The orientations of all probe and background stimuli are de—
Fig. 2. Subjects viewed the display through a shroud that obscured all peripheral ﬁHEd Wlth respect to the. bOdy.mld_lme Of the Observér' Zero. cle—
vision, masked the screen to a 285° diameter circle and set the viewing distance at gree mfers t0 the orientation Of the bOdy aXIS' POSltlve
25 cm. Participants responded using the buttons on a game pad, visible on the desk. orientations are CTOCkWTSE (‘rightward5’) TETatTVE to this TETETEHCE

"
"4","2134 B. Haji-Khamneh, LR. Harris/ Vision Research 49 (2009) 2131—2139
\\
. v -’
,1 I, I
1' K "" .
' ' I
' ‘- f
I
l I ’ I
l I
\ ' ‘
\ a.
\ .
\ .
x l
100 ms \
K
\ MMVI
\\ “£343?"" 3‘1”}
50, 75, 150 or 500 ms \ ”*’
\
x
x
\
x
100 ms \
\
\
response: ‘p’ or ‘d’
Fig. 3. The sequence of events in a typical trial. After ﬁxation point offset, participants saw the stimulus, a composite of background and probe, for 50, 75, 150 or 500 ms.
Stimulus offset was followed by a structure mask for 100 ms and then a grey screen with the ﬁxation point. The background image was presented in color.
3 Perceptual Upright being 00 when the vertical shaft of the symbol is aligned with
2100% : ' ' - ' : the body axis with the letter bowl to the right (i.e., when the char-
° ' o ' , _ acter was resented as an u ri ht ‘ ’ .
% 75% d-p transiliio p-(ﬁtransmon p p g p )
d.)
1. I I
.Q 50% ________ _______.| .________ 3. Results
3. . :
g 25% : . 3.1. Character identiﬁcation
C” i
(U 0 . . . .
E O A : ° ' T0 establlsh that the probe could be Identlﬁed at the dlfferent
8 presentation times used in this study we measured identiﬁcation
8 _ o _ o _ o o o o a performance for a range of stimulus onset asynchronies SOAs .
a 180 120 60 o 60 120 180 . . .
d 9 Q p «o b d The percentage of accurate character 1dent1ﬁcat10n was calculated
Character Orlentatlon (deg) for each SOA for each participant. The average across all partici-
' ' f h im 1 —m k n n-
Fig. 4. Typical psychometric functions obtained from a single background orien— pﬁnts IS pIOt.tEd as a fUIthon O t e St u us is. O SGEt asy
tation (in this case upright) and presentation time (in this case 150 ms). The C rony (t) m Flg' 5' two-parameter cumu atlve aUSSIan
percentage of times the character was identiﬁed as a ‘p’ is plotted against its fUHCtlon 0“ a 50% DEdEStal
orientation. Cumulative Gaussians were plotted through the data from which the 50
two points of maximum ambiguity (the 50% point) were found (in this case, at y = 50 + % (2)
—90.1° and +85.8o indicated on the graph by vertical clashed arrows). The 1+e‘(t_t75)/b
perceptual upright is deﬁned as being half way between these orientations (2.1o _
in this example, illustrated by the solid arrow) was ﬁtted to these data where t75 corresponds to the presentatlon
time at which subjects were 75% correct threshold and b is the stan-
orientation, negative orientations are counter-clockwise (‘left- dard deviation. The mean presentation time at which participants
wards’), as seen by the observer. The ‘p’ symbol is described as were able to correctly identify the character 75% 0f the time was

"
"5","B. Haji—Khamneh, LR. Harris/ Vision Research 49 (2009) 2131—2139 2135
3.2. The effect of visual background orientation on PU
100% I . . . . .
'8 ,_._,_,_,_,_, ._._,_, ,_.___,i_,_,_,_ The orlentatlon of the PU 1S plotted as a functlon of the enema—
2 tion of the visual background for each of the four stimulus—mask
a onset asynchronies in Fig. 6. The open symbols with standard error
0 0 bars are the average of the data from all eight participants. The PU
E 75 /° _ — _ _ _ _ — _ _ — _ _ — _ _ _ was strongly inﬂuenced by the orientation of the visual back—
8 ground, varying by more than $160 at all stimulus—mask onset
a asynchronies. The solid line ﬁtted through the data is the model
0. ﬁt (see below, Section 3.4).
50%
3.3. The effect of adaptation 0n the PU
0 20 40 60 80 The effects of adaptation 0n PU were tested by analyzing data
Stimu|us-mask onset asynchrony (m5) from the ﬁrst and second half of each participant’s data session
separately and comparing the just noticeable differences (jnd)
Fig. 5. Time to identify the probe Character. The percentage of times the probe was and the points of maximum ambiguity of the ﬁrst sample With that
correctly identiﬁed is plotted asafunction of stimulus—mask onset asynchrony. 75% Of the second sample The early and late samples were also com_
correct performance was reached at 29.6 ms as indicated by the vertical line. Data d h 11 “d . h h
points represent the mean proportion of correct responses over 20 trials averaged pare to t e overa ata Wlt _ respect F0 t ESE. parameters. For
across all eight participants. The 50%, 75% and 95% responding levels are indicated the early and late 5311113195, HEIthEI‘ the JUSt HOtlceable dlfference
by horizontal dashed lines. of the psychometric judgments nor the points of maximum ambi—
guity were signiﬁcantly different from each other (p = .88 and .93,
respectively). Likewise, the early and late samples did not differ
29.6 mg as shown by the vertical line in Fig, 5, Participants were signiﬁcantly from the overall data either with respect to theirb val—
capable of identifying the probe 95% of the time at the shortest U65 (13 = -75) or With FESPECt t0 thEiF points 0f maximum ambiguity
OCHART viewing condition used for the main experiment (50 ms). (13 = 33)-
a) b)
§ 40 50 ms 40 75 ms
3
E 20 20
.9) § E E
a W W
D O .0... I O .00... O. O .0... 0...... 000...... 0.
Tu
3
3- 20 -20
(D _
8
8
-4O -4O
-90 0 90 180 270 360 -90 O 90 180 270 360
c) d)
a 40 150 ms 40 500 ms
0)
3
E 20 20
.9
E.
D 0 000.0% 0 Icon. cocoa... ouogj
Tc
3
'5. -20 -20
d)
O
I—
3
-40 -4O
-90 0 90 180 270 360 -90 O 90 180 270 360
Backg round Orientation (deg) Backg VOUNd Orientation ((199)
Fig. 6. This ﬁgure illustrates how the orientation of the PU (vertical axis) changes with the orientation of the background scene (horizontal axis) for stimulus—mask onset
asynchronies of (a) 50 ms, (b) 75 ms, (c) 150 ms and (d) 500 ms. The grey clots represent the PU at each background orientation for each participant (obtained as shown in
Fig. 4). The means are depicted by the open circles with corresponding standard errors. The solid curves are the lines of best ﬁt of the vector sum model (see text and Fig. 7).

"
"6","2136 B. Haji—Khamneh, LR. Harris/ Vision Research 49 (2009) 2131—2139
3.4. Vector model a)
We modeled the effect of visual cues on the PU using the 20
weighted vector model described in Dyde et al. (2006). In this a;
model the orientation of the body, gravity, and visual cues are E 15
treated as vectors in their veridical directions with lengths pro— _:
portional to their relative weights. The orientation of the PU is '5') . polarizing cues
then predicted from the vector sum of these three vectors. We ex— 8 10 O horizon cues
tended this model by breaking down the visual vector into its _l 0 0 frame cues
individual components, namely the extrinsic polarizing cues, the '5
horizon cues, and the frame cues. The model does not include *5 5
the light—from—above direction as a separate vector. This extrinsic (D _ -----------O
cue was present in our background scene (Fig. 3) and its contribu— > O""'8u-- .0
tion would be part of the ‘polarizing cue’. The vector that repre— 0 O
sents the direction indicated by the extrinsic polarizing cues 100 1000
corresponds to the orientation of the visual background. There— .
fore, this vector aligns itself with gravity only once as the back— Stlmulus-mask onset asynChrony (ms)
ground makes one revolution. The horizon cue however, aligns
twice as the background makes each revolution and the frame b)
cue aligns four times (see Fig. 1). Since observers were tested only A 100
in the upright body orientation, the body vector and the gravity :0
vector were always aligned. For the present study we therefore g 80
treated these two as a single vector of unity length and expressed +-
the lengths of the other three vectors relative to this gravity/body S 60
axis vector. Each vector length was then converted into a percent— '55
age of the sum total of all the vector lengths for that condition. 5 40
This model, with three free parameters corresponding to the 0
lengths of the three visual vectors, was then ﬁtted to the data q;
describing the orientation of the PU for each background orienta— E 20
tion using an established optimization algorithm (the Marquardt— i:
Levenberg technique, see Press, Flannery, Teukolsky, 82 Vetterling, 0
1988). Three parameters were thus obtained for each participant polarizing horizon frame
and each SOA. The solid line plotted through the data in Fig. 6 Cue Type
shows the output of this model plotted through all the data for
eaCh Presentation time- The regression COEfﬁCientS were 0-14, Fig. 7. (a) The length of each of the three visual vectors are plotted as a function of
0,36, 0,56 and 0,68 for the 50, 75, 150 and 500 ms SOAs, stimulus—mask onset asynchrony for each stimulus—mask onset asynchrony. They
respectively. are modeled with exponential ﬁts shown as a blaek line throngh ﬁlled data points
The mean amplitude O f each Of the three visual vectors obtained 1for polar1z1ng cues, grey l1ne through grey data p01nts for hor120n cues and dashed
, _ me through open data p01nts for frame cues. The standard errors for these data
for eaCh SUbJECt and eaCh SOA W35 compamd usmg repeatEd'mea' points (from 0.016 to 0.02) were too small to be depicted graphically. (b) The mean
sures ANOVA With the visual CUES (polarizing VS. hOI‘iZOH VS. frame) time constants were averaged across participants (n = 8) and shown here as a bar
as the within—subjects factors. The main effect of visual component Chart with standard error bars. The mean time constants were 68.9, 51.7 and
on vector length was signiﬁcant 13(1073’ 3.219) = 51.793, p = .004. 68.7 ms for polarizing, horizon and frame cues, respectively.The 95% conﬁdence
Paired sample t—tEStS revealed that while the mean vector length 1fntervals for the t1me constants were 33—103 ms for the polar1z1ng cues, 16—86 ms
or the hor120n cues and 26—90 ms for the frame cues. No 51gn1ﬁcant d1fference was
for polarizing cues was signiﬁcantly different from the mean vector found between time constants_
length for the horizon cues t(3) = 8.217, p= .004 as well as the
frame cues t(3) = 6.693, p = .007, the weightings of the latter cues
were not signiﬁcantly different from each other t(3) = —.37, 4. Discussion
p = .731.
4.1. Summary
3-5- Presentation time and the inﬂuence of visual cues 0"" PU The background image evoked shifts in the perceptual upright
(PU) linked to each of the three classes of visual orientation cues
In order to describe the amount 0f time that each component contained in the picture: extrinsic polarizing cues and intrinsic
needed to exert itS effect on the perceptual upright we ﬁtted an horizon and frame cues. The polarizing cues had the most inﬂuence
exponential 8F0Wth fUHCtiOH t0 the length 0f each visual VECtOF on the orientation of the PU as evidenced by the longer length of
for each participant plotted as a fUthiOh 0f stimulus—mask OHSEt the vector associated with this cue. The different extent to which
asynchrony (Fig. 73) Time constants were obtained for exponential each visual cue affects the PU is likely to at least partially depend
growth 0f each visual component and averaged across participants on the content of the visual image. If there are fewer structural
as summarized in Fig. 713- A repeated—measures ANOVA comparing cues visible, for example, then it is likely they will have a relatively
the time constants 0f extrinsic polarizing cues (M = 58-7 ms, 95% smaller effect. However, the relative lengths of the vectors do not
conﬁdence interval = 33-103 ms), horizon cues (M = 51-7, 95% COH- concern us here. What is interesting is that the time it took for each
ﬁdence interval = 15-85 ms) and frame cues (M = 58-7, 95% COHﬁ- component to exert its effect was the same for all three cues with a
dence interval = 25-90 ms) revealed no signiﬁcant difference time constant around 60 ms (Fig. 7b). This is much longer than the
(H135, 955) = 0552,13 = 878), suggesting that 3“ fUthiOHS ih- time it took to reliably identify the letter probe (about 30 ms). The
creased at approximately the same rate With an overall mean time fact that all three components took about the same amount of time
constant of 59.7 ms. to exert their effect was surprising to us. We had expected the

"
"7","B. Haji—Khamneh, L.R. Harris/ Vision Research 49 (2009) 2131—2139 2137
intrinsic polarizing cues to take longer, based on the presumed as the ﬁrst 150 ms from stimulus onset, the visual system has al—
higher—level of processing involved. ready extracted enough meaningful information from complex

The jnd and the points of maximum ambiguity were not af— scenes to be able to perform highly demanding tasks such as cate—
fected as a result of adaptation to the single background scene that gorization (Rieger et al., 2005; Rousselet et al., 2003; Thorpe, Fize,
was used in this experiment. Thus the inﬂuence of each cue on the 82 Marlot, 1996). Our ﬁndings suggest that the effects of the scene
PU did not change as a result of adaptation. However, the use of on object orientation may be even speedier: within only 60 ms
only a single image raises other concerns with regards to the gen— from stimulus onset enough information has been extracted from
eralizability of our results especially that of the absolute values of the visual scene to inﬂuence the perception of object orientation.
our obtained time constants. Familiarity with visual stimuli has What kind of information can be adequately extracted in such a
been shown to change processing (Muller, Metha, Krauskopf, 82 short time interval as to have an impact on our visual orientation?
Lennie, 1999) and it is a plausible conjecture that processing speed Scene processing is extraordinarily fast. Twenty—four milliseconds
may differ in more natural visual environments (where every im— of undistorted processing provides sufﬁcient information to recog—
age is analyzed anew). It is important to keep this in mind for nize scenes above chance level and after 90 ms perfect recognition
the remainder of the discussion. accuracy is reached (Rieger et al., 2005). Ringach, Hawken, and

Shapley (1997) examined the temporal dynamics of the orientation
4.2. The processing time of visual orientation information tuning of V1 cells in anesthetized monkeys. They found that while
orientation tuning was ﬁrst observed 30—45 ms after stimulus on—

The time that the visual stimulus was available was limited by set, it improved over an additional 40—85 ms during which time
the use of a pattern mask. Visual processing is a dynamically tuning became progressively sharper. This range is compatible
changing phenomenon (VanRullen 82 Thorpe, 2001) and pattern with our intrinsic time constants (of 51.7 and 58.7 ms). While this
masking has been an invaluable tool in examining the various lev— coincidence may explain the magnitude of the time constants for
els of information processing(Breitmeyer82Ogman, 2006) for over the frame and the horizon components, polarized cues include
100 years (Exner, 1868). Pattern masking refers to a masking not only complex objects but also complicated and learned rela—
method in which the target stimulus spatially overlaps with and tionship between objects. The orientation tuning of V1 cells cannot
precedes the mask and the visibility of the target is limited by its be the sole underlying mechanism for their effects.
temporal proximity to the mask (Kahenman, 1968). This method Our time constants are also in accordance with results of stud—
has been used to study the recognition of simple geometric forms ies of higher—level object categorization. For example, 40—60 ms of
and faces (Lofﬂer, Gordon, Wilkinson, Goren, 82 Wilson, 2005), to stimulus duration is sufﬁcient to allow for accurate categorization
assess the time it takes to categorize (Bacon—Macé, Mace, Fabre— of scenes (Bacon—Macé et al., 2005; Fei—Fei, Iyer, Koch, 82 Perona,
Thorpe, 82 Thorpe, 2005) or recognize (Rieger, Braun, Bulthoff, 82 2007; Loschky et al., 2007). Fei—Fei et al. (2007) used a free—recall
Gegenfurtner, 2005) a scene. Here we applied pattern masking to task to probe the nature of information that is accessible during
the use of orientation information. We adopted the notion that scene categorization. They found that, while the viewers’ open—
psychophysical applications of masking have traditionally as— ended descriptions of brieﬂy ﬂashed scenes were dominated by
sumed: that the mask essentially erases and/or adds noise to the low—level sensory descriptors at short stimulus onset asynchronies,
target stimulus at early pre—cortical visual areas to effectively ter— subjects used more object—related and semantic language to de—
minate its further processing (e.g., Carrasco, Williams, 82 Yeshurun, scribe what they saw at longer presentation times. The transition
2002; Rauschenberger 82 Yantis, 2001; Rieger et al., 2005). That is, occurred somewhere between 40 and 67 ms. Other researchers
we make the assumption that there exists an early representation found a similar temporal window for maximal scene categorization
of the stimulus in a sensory buffer that encodes the physical attri— accuracy between 40 and 81 ms using an ERP paradigm (Bacon—
butes of the stimulus (Marr, 1982). This template is constantly pro— Mace et al., 2005). Rieger, Koechy, Schalk, Grueschow, and Heinze
cessed by higher cognitive centers at increasingly abstract levels (2008) found that at least 50 ms of undistorted information accu—
(Lamme 82 Roelfsema, 2000; Rieger et al., 2005). The mask would mulation is necessary for the effect of scene—object orientation
disrupt processing by replacing the template of the target with incongruence on reaction time to emerge. They deemed it likely
its own. The stimulus—mask onset asynchrony is the critical vari— that this effect emerges at the junction in processing when infor—
able. We conclude from our experiments that the processing time mation regarding both orientation (De Caro 82 Reeves, 2000,
(taken as the time constant of growth) of each visual component is 2002; Hamm 82 McMullen, 1998) and scene semantics (Ganis 82 Ku—
approximately the same at around 60 ms: that is that the scene tas, 2003; Henderson 82 Hollingworth, 2003) ﬁrst became accessi—
needs to be visible for about 60 ms (a stimulus—mask onset asyn— ble. Taken together, these studies suggest that our time constants
chrony of 60 ms) for both intrinsic and extrinsic cues to be avail— of 50—70 ms may reﬂect a surprisingly speedy object categoriza—
able. The fact that there was no systematic difference between tion mechanism which carries sufﬁcient information, including
them suggests parallel extraction of the three components, since that pertaining to orientation and semantics, to identify an object’s
a serial extraction (in which higher—level cues are constructed from polar axis and specify the extrinsic cues to orientation. However,
lower—level ones) would have resulted in cumulative time effects whether this ﬁnding holds for natural processing of non—familiar
with higher—level cues taking the time it took to process the low— scenes is an empirical question.
er—level ones plus the time it took to combine those cues.

4.4. The importance of the background for object processing
4.3. Comparison with other timings in vision
A visual scene contains intrinsic and extrinsic cues that provide

Fast and accurate object recognition is critical to our survival in orientation information and also deﬁne what kind of scene it is.
the real world. An object is typically embedded in a global scene The relative contribution of higher—level extrinsic and lower—level
containing many other objects as well as other features. Much re— intrinsic orientation cues in determining a scene, and its subsequent
search has focused on elucidating the time course of object recog— effect on the perception of objects within the scene, is not estab—
nition (Biederman, 1972; Mumford, 1994; Rao 82 Ballard, 1999; lished. Low—level properties of scenes such as color(Delorme,Rich—
Rosch, 1976) as well as that of scene perception (Biederman, ard, 82 Fabre—Thorpe, 2000; Gegenfurtner 82 Rieger, 2000) and
Mezzanotte, 82 Rabinowitz, 1982; Hegde, 2008; Joubert et al., orientation (Rousselet et al., 2003; Vuong et al., 2006) do not seem
2007). Taken together, these studies suggest that within as little capable of disrupting object classiﬁcation. Rousselet et al. (2003)

"
"8","2138 B. Haji—Khamneh, LR. Harris/Vision Research 49 (2009) 2131—2139

found only marginal effects of scene inversion on face/animal classi— Asch, S._E., 82 Witkin. H. A. (1948a). Studies in Space orientation- 1- Perception of the
ﬁcation fOI‘ brieﬂy ﬂashed scenes and Vuong et al. (2006) found no 9321§§§7w1th d1splaced v1sual ﬁelds. journal of Expenmental Psychology, 38(3),
SUCh EffECtS Oh the dEtECtion Of humans in a scene- By contrast, a re— Asch, S. E., 82 Witkin, H. A. (1948b). Studies in space orientation. 2. Perception of the
cent Study Rieger et al. (2008) found that scene rotation (but not upright with displaced visual ﬁelds and with body tilted. journal of Experimental
inversion), as well as incongruence between object and scene orien— PsyChOI‘Bgy' 38(4)',455‘477- ,

. h . h. . ff . 1 'ﬁ . h h Bacon—Mace, N., Mace, M. J. M., Fabre—Thorpe, M., 82 Thorpe, 5.]. (2005). The t1me
tathh, ad an m lbltOI:y 6 ea Oh ObJECt C 51551 cation. Furt er t ey course of visual processing: Backward masking and natural scene
found that the processmg of objects embedded Within a scene was categorization. Vision Research, 45(11), 1459—1469.
disrupted when the object was upright and the scene was rotated, Biederman, I. (1972). Perce1v1ng real—world scenes. Saence, 177(4043), 77—80.

. h b. . l. h .1 . . B1ederman, I., Mezzanotte, R. J., 82 Rab1now1tz, J. C. (1982). Scene percept1on —
suggestingt aFO JECt processmg re leS. eaVI yon scene orientation. Detecting and judging objects undergoing relational violations. Cognitive
In the same vein, Dyde et al. (2006), usmg the OCHART letter probe, Psychology, 14(2), 143—177.
and Mittelstaedt (1999) and (ASCh & Witkin, 19488, 1948b) using a Breitmeyer,-B., 82 ngan, H. (2006). Visual masking: Time slices through conscious and
rod showed that scene orientation can affect the erceived orienta— unconscwus mm"" and ed.). New York: OXford Unwersny Press“

_ ’ . _ p Biilthoff, H. H., 82 Mallot, H. A. (1987). Interaction of different modules in depth
tion of embedded objects. These effects of the Visual background rep— perception. In First international conference on computer vision, London, England
resent composite effects of all the components, both high—level (1313- 295-305_)-_ _ _
(extrinsic) and low—level (intrinsic) of the visual scene. The present carrasco.’ M"" Wllltams’ .P' E"" 8’ YEShurun’ Y‘ 9002) covert.atte““°“ Increases

_ _ _ _ _ spat1al resolut10n w1th or w1thout masks. Support for s1gnal enhancement.
study represents the ﬁrst attempt to isolate the 1nd1v1dual contnbut— journal of Vision, 2, 1-4;
ing components within a natural scene, Cohen, J., lVIacWhinney, B., Elatt, M., 82 Provost, J. (1993). .Psyscope — An interactive

Traditionally, scene recognition has been thought of as the culmi— graph” system for deglgmng and contronmg. exPer‘ments 1“ the pSyChOIOgy

t. f b tt f' f t. t t. A Cl. laboratory us1ng Mac1ntosh computers. Behawor Research Methods Instruments
na 1011 O a 0 0111—111) process 0 1n orma 101] EX rac 1011. CCOT mg and Computers, 25(2), 257_271_
to this proposition, early low—level modules such as contour detec— De Caro, _S. A., 82 Reeves, A. (2000). Rotating Objects to determine orientation, not
tion, shade perception, and stereo perception, are integrated to give eiznggc'hgggesicse 6g??? 31‘ 3'35a6C1<;’V336r6C1'ma51<1“g/ dual'taSk Procec‘ure- Perception
Use t01nd1v1dual ObJECtS- These (?bJECtS are m tum COIhblhed t0 glve DeCaro, S. A., 82 Reeves, A. (2002). The use of word—picture veriﬁcation to study
rise tO high—level scene recognition (BtllthOffgz Mallot, 1987; Driver entry—level object recognition: Further support for view—invariant mechanisms.
82 Baylis, 1996; Hildreth 82 Ullman, 1993; Marr, 1982; Nakayama, He, Memory and cognition, 30(5) 811—821 _ _ _

& Sh. . 1995) S f t l l t. f Delorme, A., R1chard, G., 82 Fabre—Thorpe, M. (2000). Ultra—rap1d categor1sat1on of
lmOjO, . ensory— or ea ure— eve pioper ies 0 5% scene, natural scenes does not rely on colour cues: A study in monkeys and humans.

such as shape, are perceived faster than spatial—relationships and Vision Research, 40(16), 2187—2200.

semantic—level information (Fei—Fei et al., 2007). The present ﬁnding WY“, 1., 82 Baylis, ?- C- (1995); Edge-aséignment and ﬁgure-gmund segmentation

rroborate a arallel rocessin model of scene rocessin since m Shoreterm Vlsual matChmg' eogmtwe PSyChOlOgy’ 31(3)’ 248—306
CO _ p _ ‘1) g p g Dyde, R. T., Jenkin, M. R., 82 Harris, L. R. (2006). The subjective visual vertical and the
lOWEf—lEVEl Informatlon SUCh as the Structural frame Of the scene perceptual upright Experimental Brain Research, 173(4), 612—622_
and the horizon were found to be processed at the same speed as Exner, S. (1868).beer die 1zu einer gesiclhtswahrnehsmung nbothige zehit [On the timce

- _ - - necessary or visua perception . Wiener itzungs er Mat —Naturwiss
the higher level polarized Objeets' Kaiserlichen Akad Wiss, 58(2), 601—632.
Fei—Fei, L., Iyer, A., Koch, C., 82 Perona, P. (2007). What do we perceive in a glance of a
45 Conclusions real—world scene? journal of Vision, 7(1), 10.
Ganis, G., 82 Kutas, M. (2003). An electrophysiological study of scene effects on
_ _ object identiﬁcation. Cognitive Brain Research, 16(2), 123—144.

In summary2 we have shown that all three Vlsual cues to orien— Gegenfurtner, K. R., 82 Rieger,]. (2000). Sensory and cognitive contributions of color
tation are processed at approximately the same rate (50—70 ms) at to the recognition of natural scenes. Current Bi.ology,.10(13), 805—808. .
least for a familiar image. This processing time range may reﬂect Hamm,]. P., 82 McMullen, P. A. (1998). Effects of or1entat1on on the 1dent1ﬁcat1on of

. . . . . . rotated objects depend on the level of 1dent1ty. journal of Experlmental
an exeeedingly rapid categorization meehanisna 1n the case of the Psychology _ Human Perception and Performance, 24(2), 4134126
polarized cues, and low—level OI‘lehtathh tuning 111 the case Of Hegde,]. (2008). Time course of visual perception: Coarse—to—ﬁne processing and
the frame and the horizon cues. That all cues are processed at beyond- Progress m Neumbwlogy, 8441405439 _

h C1 C1. h . h l . b. . Henderson, J. M., 82 Holl1ngworth, A. (2003). Eye movements, v1sual memory, and
t 6 same spee contra .lCtS t Berles t at C alm 0 Ed perception scene representation. In M. A. Peterson 82 G. Rhodes (Eds.), Perception offaces,
precedes scene perception and instead our data support parallel— objects, and scenes:Analytic and holistic processes (pp. 356—377). New York, NY,

rocessin of ob'ects and contexts. Moreover, des ite their e uiv— U52 OXfOFd UniVEFSitY Press-
aplent rocgessin JS eed olarized C es are the H101; salient qu in Hildreth, E. C., 82 Ullman, S. (1993). The computational study of vision. In E. C.

p_ _ g p ’ p _ u _ _ u _ Hildreth 82 S. Ullman (Eds.), Foundations ofcognitive neuroscience (pp. 581—630).
determining the perceptual upright. That all of this information Cambridge, MA; MIT press_
is extracted from the visual environment and perhaps assessed Jolicgeurt _P- (1123);; 351316 to name disoriented natural objectS- Memory and

- - - - ogmtlon, , — .

fOI‘ usefelness In less _than 100 1115, ImPheS that the bram has: the Joubert, O. R., Rousselet, G. A., Fize, D., 82 Fabre—Thorpe, M. (2007). Processing scene
EXtraordmary capability Of dealmg Wlth a vaSt amount 0f Vlsual context: Fast categorization and object interference. Vision Research, 47(26),
information and clutter in just a glance. Further experiments are 3286-3297- _ _ _ _ _
required tO illuminate the speed and nature Of processing Of extrin— I(ahenman, D. (1968). Method, ﬁnd1ngs, and theory 1n stud1es of v1sual masl<1ng.

. . . . . _ _ Psychologlcal Bulletin, 70(6, Pt. 1), 404—425.
51C and lhtI‘thlC cues In more natural Vlsual env1ronments. A1502 Lamme, V. A. F., 82 Roelfsema, P. R. (2000). The distinct modes of vision offered by
the relative contribution and speed Of processing Of the light— feed—forward and recurrent processing. Trends in Neuroscience, 23, 571—579.
above—prior warrants further investigation Lofﬂer, G., Gordon, G. E., Wilkinson, F., Goren, D., 82 Wilson, H. R. (2005). Conﬁgural

' masking of faces: Evidence for high—level interactions in face perception. Vision
Research, 45(17), 2287—2297.
Acknowledgments Loschky, L. C., Sethi, A., Simons, D. J., Pydimarri, T. N., Ochs, D., 82 Corbeille, J. L.
(2007). The importance of information localization in scene gist recognition.
These experiments were supported by the Natural Sciences and journal of Experimental Psychology — Human Perception and Performance, 33(6),
1431—1450.
Engineering Research Council Of Canada (NSERC) and the Canadian MacWhinney, B., Cohen, J., 82 Provost, J. (1997). The PsyScope experiment—building
Space Agency (CSA). We would like to give special thanks to Rich— SYStém- Spatial V1510"", 1 12 99-101- _ _ _ _ _ _
. . . . Mamass1an, P., 82 Goutcher, R. (2001 ). Pr1or knowledge on the 1llum1nat1on pos1t1on.
ard Dyde and Michael Barnett—Cowan for their help in setting up Cognition 81(1) m_Bg
and running thiS project. Marr, D. (1982). Vision: A computational investigation into the human representation
and processing of visual information. New York: W. H. Freeman and Co.
McIntyre, ]., Zago, M., Berthoz, A., 82 Lacquaniti, F. (2001). Does the brain model
References Newton’s laws? Nature Neuroscience, 4(7), 693—694.
McMullen, P. A., 82]olicoeur, P. (1992). Reference frame and effects of orientation on
Adams, W. J., Graf, E. W., 82 Ernst, M. O. (2004). Experience can change the ‘light— ﬁndingthe tOPS 0f rotated ObJECtS-JOUTHGI ofExperimental Psychology — Human
from—above’ prior. Nature Neuroscience, 7(10), 1057—1058. PeTCBPUOTI and Performance, 18(3). 807-820.

"
"9","B. Haji—Khamneh, LR. Harris/ Vision Research 49 (2009) 2131—2139 2139

Mittelstaedt, H. (1983). A new solution to the problem of the subjective vertical. discrimination dynamics. journal of Experimental Psychology — Human
Naturwissenschaften, 70(6), 272—281. Perception and Performance, 34(1), 56—76.

Mittelstaedt, H. (1986). The subjective vertical as a function of visual and Rieger,]. W., Braun,C.,Bi11thoff, H. H., 82 Gegenfurtner, K. R. (2005). The dynamics of
extraretinal cues. Acta Psychologica, 63(1—3), 63—85. visual pattern masking in natural scene processing: A

Mittelstaedt, H. (1999). The role of the otoliths in perception of the vertical and in magnetoencephalography study. journal of Vision, 5(3), 275—286.
path integration. Annals of the New York Academy of Sciences, 871, 334—344. Ringach, D. L., Hawken, M.]., 82 Shapley, R. (1997). Dynamics of orientation tuning in

Muller, J. R., Metha, A. B., Krauskopf, J., 82 Lennie, P. (1999). Visual adaptation in macaque primary visual cortex. Nature, 387(6630), 281—284.
visual cortex to the structure of images. Science, 285, 1405—1408. Rosch, E. (1976). Basic objects in natural categories. Cognitive Psychology, 8(3),

Mumford, D. (1994). Large—scale neuronal theories of the brain. In C. Koch 82]. L. 382—439.

Davis (Eds.), Neuronal architectures for pattern—theoretic problems (pp. 125—152). Rousselet, G. A., Joubert, O. R., 82 Fabre—Thorpe, M. (2005). How long to get to the
Cambridge, MA, US: The MIT Press. “gist"" of real—world natural scenes? Visual Cognition, 12(6), 852—877.

Nakayama, I<., He, Z.]., 82 Shimojo, S. (1995). Visual surface representation: A critical Rousselet, G. A., Mace, M. J. M., 82 Fabre—Thorpe, M. (2003). Is it an animal? 15 it a
link between lower—level and higher—level vision. In S. M. Kosslyn 82 D. N. human face? Fast processing in upright and inverted natural scenes. journal of
Osherson (Eds.), Visual cognition: An invitation to cognitive science, (2nd ed., Vol. Vision, 3(6), 440—455.

2, pp. 1—70). Cambridge, MA, US: The MIT Press. Schwarzkopf, D. S., 82 Kourtzi, Z. (2008). Experience shapes the utility of natural

Oliva, A., 82 Schyns, P. G. (2000). Diagnostic colors mediate scene recognition. statistics for perceptual contour integration. Current Biology, 18(15),
Cognitive Psychology, 41(2), 176—210. 1162—1167.

Press, W. H., Flannery, B. P., Teukolsky, S. A., 82 Vetterling, W. T. (1988). Numerical Steeves, J. K. E., Humphrey, G. I(., Culham, J. C., Menon, R. S., Milner, A.
recipes in C: The art of scientiﬁc computing. New York: Cambridge University D., 82 Goodale, M. A. (2004). Behavioral and neuroimaging evidence for
Press. a contribution of color and texture information to scene classiﬁcation

Ramachandran, V. S. (1988). Perception of shape from shading. Nature, 331(6152), in a patient with visual form agnosia. journal of Cognitive Neuroscience,
163—166. 16(6), 955—965.

Rao, R. P. N., 82 Ballard, D. H. (1999). Predictive coding in the visual cortex: A Thorpe, S., Fize, D., 82 Marlot, C. (1996). Speed of processing in the human visual
functional interpretation of some extra—classical receptive—ﬁeld effects. Nature system. Nature, 381 (6582), 520—522.

Neuroscience, 2(1), 79—87. VanRullen, R., 82 Thorpe, S. J. (2001). The time course of visual processing: From

Rauschenberger, R., 82 Yantis, S. (2001). Masking unveils pre—amodal completion early perception to decision—making. journal of Cognitive Neuroscience, 13(4),
representation in visual search. Nature, 410(6826), 369—372. 454—461.

Rieger,]. W., Koechy, N., Schalk, F., Grueschow, M., 82 Heinze, H. (2008). Speed limits: Vuong, Q. C., Hof, A. F., Bﬂlthoff, H. H., 82 Thornton, I. M. (2006). An advantage for
Orientation and semantic context interactions constrain natural scene detecting dynamic targets in natural scenes. journal of Vision, 6(1), 87—96.

"
